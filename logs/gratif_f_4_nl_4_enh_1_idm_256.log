INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=4, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='mimiciv')
INFO:root:{'input_dim': 100, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.8060880899429321 VAL: 0.36456498503685
INFO:root:2
Train: 0.2905387282371521 VAL: 0.278323769569397
INFO:root:3
Train: 0.2752235531806946 VAL: 0.27599310874938965
INFO:root:4
Train: 0.26548364758491516 VAL: 0.26471278071403503
INFO:root:5
Train: 0.2585202753543854 VAL: 0.26045286655426025
INFO:root:6
Train: 0.25429755449295044 VAL: 0.2607704997062683
INFO:root:7
Train: 0.25147899985313416 VAL: 0.2520889937877655
INFO:root:8
Train: 0.24548892676830292 VAL: 0.25004783272743225
INFO:root:9
Train: 0.24381791055202484 VAL: 0.24728265404701233
INFO:root:10
Train: 0.24033674597740173 VAL: 0.2509085536003113
INFO:root:11
Train: 0.24025435745716095 VAL: 0.2412049025297165
INFO:root:12
Train: 0.2365916222333908 VAL: 0.2538459002971649
INFO:root:13
Train: 0.23586677014827728 VAL: 0.2464529275894165
INFO:root:14
Train: 0.23244665563106537 VAL: 0.24370267987251282
INFO:root:15
Train: 0.23076333105564117 VAL: 0.23673756420612335
INFO:root:16
Train: 0.23054145276546478 VAL: 0.2424764633178711
INFO:root:17
Train: 0.22942860424518585 VAL: 0.2420935481786728
INFO:root:18
Train: 0.2269294559955597 VAL: 0.24124129116535187
INFO:root:19
Train: 0.22755052149295807 VAL: 0.23925289511680603
INFO:root:20
Train: 0.22599975764751434 VAL: 0.2393011450767517
INFO:root:21
Train: 0.22741301357746124 VAL: 0.242155522108078
INFO:root:22
Train: 0.22441557049751282 VAL: 0.24681249260902405
INFO:root:23
Train: 0.22203417122364044 VAL: 0.23303593695163727
INFO:root:24
Train: 0.22307297587394714 VAL: 0.23474746942520142
INFO:root:25
Train: 0.22444546222686768 VAL: 0.24741294980049133
INFO:root:26
Train: 0.22204650938510895 VAL: 0.24619647860527039
INFO:root:27
Train: 0.22686046361923218 VAL: 0.2348085343837738
INFO:root:28
Train: 0.22411757707595825 VAL: 0.2372412383556366
INFO:root:29
Train: 0.22129178047180176 VAL: 0.2324570119380951
INFO:root:30
Train: 0.222269207239151 VAL: 0.23953987658023834
INFO:root:31
Train: 0.22589832544326782 VAL: 0.23639580607414246
INFO:root:32
Train: 0.2265172153711319 VAL: 0.2393636405467987
INFO:root:33
Train: 0.22897350788116455 VAL: 0.2408483922481537
INFO:root:34
Train: 0.37529781460762024 VAL: 125.29475402832031
INFO:root:35
Train: 14197633024.0 VAL: 515248.0625
INFO:root:36
Train: 375337.34375 VAL: 201446.828125
INFO:root:37
Train: 167537.625 VAL: 130964.546875
INFO:root:38
Train: 116442.0546875 VAL: 89384.265625
INFO:root:39
Train: 73752.21875 VAL: 61715.359375
INFO:root:40
Train: 55286.03515625 VAL: 47913.390625
INFO:root:41
Train: 51879.8671875 VAL: 48170.4609375
INFO:root:42
Train: 52082.1015625 VAL: 49907.40625
INFO:root:43
Train: 43731.2421875 VAL: 32144.259765625
INFO:root:44
Train: 65747.84375 VAL: 763046.875
INFO:root:45
Train: 501383.84375 VAL: 234460.90625
INFO:root:46
Train: 184308.40625 VAL: 191481.625
INFO:root:47
Train: 131731.6875 VAL: 159693.1875
INFO:root:48
Train: 83957.9140625 VAL: 74279.703125
INFO:root:49
Train: 58024.92578125 VAL: 47748.61328125
INFO:root:50
Train: 48205.046875 VAL: 37454.3515625
INFO:root:51
Train: 44596.83203125 VAL: 51122.578125
INFO:root:52
Train: 12056186.0 VAL: 751562.1875
INFO:root:53
Train: 197233.328125 VAL: 99878.234375
INFO:root:54
Train: 111496.1171875 VAL: 97747.7265625
INFO:root:55
Train: 86535.796875 VAL: 161445.6875
INFO:root:56
Train: 68313.4453125 VAL: 49278.9375
INFO:root:57
Train: 74070.453125 VAL: 85760.0625
INFO:root:58
Train: 72262.34375 VAL: 41678.0
INFO:root:59
Train: 96950.1875 VAL: 34759.875
INFO:root:BEST VAL: 34759.875 TEST : 0.23220105469226837
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=4, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 1.3346132040023804 VAL: 0.3771994411945343
INFO:root:2
Train: 0.3246752917766571 VAL: 0.298656702041626
INFO:root:3
Train: 0.30646267533302307 VAL: 0.304554283618927
INFO:root:4
Train: 0.30152612924575806 VAL: 0.29379984736442566
INFO:root:5
Train: 0.30019137263298035 VAL: 0.29671233892440796
INFO:root:6
Train: 0.30216920375823975 VAL: 0.29488858580589294
INFO:root:7
Train: 0.30040088295936584 VAL: 0.30105143785476685
INFO:root:8
Train: 0.2970317602157593 VAL: 0.2970285415649414
INFO:root:9
Train: 0.29656392335891724 VAL: 0.29311785101890564
INFO:root:10
Train: 0.29478955268859863 VAL: 0.29309287667274475
INFO:root:11
Train: 0.2924511134624481 VAL: 0.29212355613708496
INFO:root:12
Train: 0.29420530796051025 VAL: 0.29220300912857056
INFO:root:13
Train: 0.2919355630874634 VAL: 0.2907331585884094
INFO:root:14
Train: 0.2917153537273407 VAL: 0.28990638256073
INFO:root:15
Train: 0.2916473150253296 VAL: 0.28925883769989014
INFO:root:16
Train: 0.28990882635116577 VAL: 0.2899431586265564
INFO:root:17
Train: 0.2898334264755249 VAL: 0.29401180148124695
INFO:root:18
Train: 0.28866544365882874 VAL: 0.28868696093559265
INFO:root:19
Train: 0.29001283645629883 VAL: 0.2890048027038574
INFO:root:20
Train: 0.2899739444255829 VAL: 0.2929912507534027
INFO:root:21
Train: 0.2896536588668823 VAL: 0.2879510521888733
INFO:root:22
Train: 0.2866170108318329 VAL: 0.2896108329296112
INFO:root:23
Train: 0.2893393337726593 VAL: 0.2886524796485901
INFO:root:24
Train: 0.28608769178390503 VAL: 0.2880949079990387
INFO:root:25
Train: 0.28629276156425476 VAL: 0.28746774792671204
INFO:root:26
Train: 0.28825536370277405 VAL: 0.28832101821899414
INFO:root:27
Train: 0.2843964397907257 VAL: 0.2913580536842346
INFO:root:28
Train: 0.28430861234664917 VAL: 0.2899262011051178
INFO:root:29
Train: 0.28248393535614014 VAL: 0.2876012325286865
INFO:root:30
Train: 0.2850894033908844 VAL: 0.2880638539791107
INFO:root:31
Train: 0.2827483117580414 VAL: 0.29249143600463867
INFO:root:32
Train: 0.2820696532726288 VAL: 0.2894807457923889
INFO:root:33
Train: 0.2833108603954315 VAL: 0.288947731256485
INFO:root:34
Train: 0.2812619209289551 VAL: 0.29713690280914307
INFO:root:35
Train: 0.2820541262626648 VAL: 0.2918214201927185
INFO:root:36
Train: 0.27923381328582764 VAL: 0.2923789620399475
INFO:root:37
Train: 0.2763841152191162 VAL: 0.289896696805954
INFO:root:38
Train: 0.27175620198249817 VAL: 0.29266440868377686
INFO:root:39
Train: 0.2722134292125702 VAL: 0.2938806414604187
INFO:root:40
Train: 0.2703653573989868 VAL: 0.2917063236236572
INFO:root:41
Train: 0.269011914730072 VAL: 0.2920451760292053
INFO:root:42
Train: 0.2688853442668915 VAL: 0.2919314205646515
INFO:root:43
Train: 0.2684662342071533 VAL: 0.29351431131362915
INFO:root:44
Train: 0.26855695247650146 VAL: 0.2942565083503723
INFO:root:45
Train: 0.2663334012031555 VAL: 0.2913115322589874
INFO:root:46
Train: 0.2674342691898346 VAL: 0.2955625653266907
INFO:root:47
Train: 0.26205652952194214 VAL: 0.2917623519897461
INFO:root:48
Train: 0.25496241450309753 VAL: 0.29242658615112305
INFO:root:49
Train: 0.25160732865333557 VAL: 0.29613304138183594
INFO:root:50
Train: 0.24948906898498535 VAL: 0.30099642276763916
INFO:root:51
Train: 0.24747681617736816 VAL: 0.2982652187347412
INFO:root:52
Train: 0.2453921139240265 VAL: 0.2994675636291504
INFO:root:53
Train: 0.24295011162757874 VAL: 0.30073967576026917
INFO:root:54
Train: 0.24282637238502502 VAL: 0.3012644648551941
INFO:root:55
Train: 0.2397843599319458 VAL: 0.3016938269138336
INFO:root:BEST VAL: 0.3016938269138336 TEST : 0.28801289200782776
