INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.692713737487793 VAL: 0.5664227604866028
INFO:root:2
Train: 0.5782912373542786 VAL: 0.4488871097564697
INFO:root:3
Train: 0.4757712781429291 VAL: 0.4202449321746826
INFO:root:4
Train: 0.4621914327144623 VAL: 0.3006943464279175
INFO:root:5
Train: 0.35302242636680603 VAL: 0.2491409331560135
INFO:root:6
Train: 0.3333209455013275 VAL: 0.24390438199043274
INFO:root:7
Train: 0.3269787132740021 VAL: 0.2469833493232727
INFO:root:8
Train: 0.3292568325996399 VAL: 0.2639397382736206
INFO:root:9
Train: 0.32113805413246155 VAL: 0.2687770426273346
INFO:root:10
Train: 0.3221251964569092 VAL: 0.265678733587265
INFO:root:11
Train: 0.2848636209964752 VAL: 0.2623395323753357
INFO:root:12
Train: 0.3137986958026886 VAL: 0.2556842565536499
INFO:root:13
Train: 0.3064867854118347 VAL: 0.2666372060775757
INFO:root:14
Train: 0.3052486479282379 VAL: 0.2725638151168823
INFO:root:15
Train: 0.31057262420654297 VAL: 0.28946757316589355
INFO:root:16
Train: 0.3035362660884857 VAL: 0.2941061854362488
INFO:root:17
Train: 0.3051297962665558 VAL: 0.30897343158721924
INFO:root:18
Train: 0.2989751398563385 VAL: 0.2989606261253357
INFO:root:19
Train: 0.3035094738006592 VAL: 0.31194859743118286
INFO:root:20
Train: 0.30444982647895813 VAL: 0.3003772497177124
INFO:root:21
Train: 0.30029985308647156 VAL: 0.29835045337677
INFO:root:22
Train: 0.2961268723011017 VAL: 0.30935466289520264
INFO:root:23
Train: 0.2830510437488556 VAL: 0.29725784063339233
INFO:root:24
Train: 0.296662300825119 VAL: 0.3109692335128784
INFO:root:25
Train: 0.2979307472705841 VAL: 0.3026759624481201
INFO:root:26
Train: 0.2856657803058624 VAL: 0.3092687129974365
INFO:root:27
Train: 0.2958277761936188 VAL: 0.3062317967414856
INFO:root:28
Train: 0.30241838097572327 VAL: 0.30508357286453247
INFO:root:29
Train: 0.30277255177497864 VAL: 0.3189554214477539
INFO:root:30
Train: 0.2970083951950073 VAL: 0.3043305575847626
INFO:root:31
Train: 0.2984640896320343 VAL: 0.3057015538215637
INFO:root:32
Train: 0.29482123255729675 VAL: 0.30822890996932983
INFO:root:33
Train: 0.2980338931083679 VAL: 0.30884498357772827
INFO:root:34
Train: 0.29551103711128235 VAL: 0.3082098960876465
INFO:root:35
Train: 0.2797546684741974 VAL: 0.308554470539093
INFO:root:36
Train: 0.2925090491771698 VAL: 0.3082159757614136
INFO:root:BEST VAL: 0.3082159757614136 TEST : 0.3640625476837158
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.4852141737937927 VAL: 0.38568115234375
INFO:root:2
Train: 0.3749576508998871 VAL: 0.33625563979148865
INFO:root:3
Train: 0.32166796922683716 VAL: 0.32529985904693604
INFO:root:4
Train: 0.30721110105514526 VAL: 0.2978515028953552
INFO:root:5
Train: 0.3016549050807953 VAL: 0.2979140877723694
INFO:root:6
Train: 0.3003997206687927 VAL: 0.29947054386138916
INFO:root:7
Train: 0.2988986372947693 VAL: 0.2983012795448303
INFO:root:8
Train: 0.2998579144477844 VAL: 0.29429739713668823
INFO:root:9
Train: 0.2976452708244324 VAL: 0.29287174344062805
INFO:root:10
Train: 0.2966926395893097 VAL: 0.29299604892730713
INFO:root:11
Train: 0.2943805158138275 VAL: 0.2915787696838379
INFO:root:12
Train: 0.29468268156051636 VAL: 0.2904636263847351
INFO:root:13
Train: 0.29336225986480713 VAL: 0.2912054657936096
INFO:root:14
Train: 0.29269081354141235 VAL: 0.29284965991973877
INFO:root:15
Train: 0.29147791862487793 VAL: 0.2899096608161926
INFO:root:16
Train: 0.29014086723327637 VAL: 0.29080602526664734
INFO:root:17
Train: 0.291176438331604 VAL: 0.29101845622062683
INFO:root:18
Train: 0.29215237498283386 VAL: 0.290271520614624
INFO:root:19
Train: 0.29122453927993774 VAL: 0.2933407425880432
INFO:root:20
Train: 0.2898527681827545 VAL: 0.2908979058265686
INFO:root:21
Train: 0.29026439785957336 VAL: 0.29252004623413086
INFO:root:22
Train: 0.2897847294807434 VAL: 0.2896941900253296
INFO:root:23
Train: 0.2887001931667328 VAL: 0.28867146372795105
INFO:root:24
Train: 0.28937819600105286 VAL: 0.2889234125614166
INFO:root:25
Train: 0.28958237171173096 VAL: 0.29243579506874084
INFO:root:26
Train: 0.2885919213294983 VAL: 0.28933316469192505
INFO:root:27
Train: 0.2893843948841095 VAL: 0.295035183429718
INFO:root:28
Train: 0.2886660695075989 VAL: 0.29146698117256165
INFO:root:29
Train: 0.2874029278755188 VAL: 0.29000169038772583
INFO:root:30
Train: 0.2862861156463623 VAL: 0.2963026165962219
INFO:root:31
Train: 0.2873193025588989 VAL: 0.2932320237159729
INFO:root:32
Train: 0.28669196367263794 VAL: 0.28908437490463257
INFO:root:33
Train: 0.28571444749832153 VAL: 0.2903388738632202
INFO:root:34
Train: 0.28582555055618286 VAL: 0.29244470596313477
INFO:root:35
Train: 0.28347480297088623 VAL: 0.2892480492591858
INFO:root:36
Train: 0.28387609124183655 VAL: 0.28921324014663696
INFO:root:37
Train: 0.2827795147895813 VAL: 0.28864598274230957
INFO:root:38
Train: 0.281960666179657 VAL: 0.28994885087013245
INFO:root:39
Train: 0.2828912138938904 VAL: 0.28898370265960693
INFO:root:40
Train: 0.2825281023979187 VAL: 0.28878873586654663
INFO:root:41
Train: 0.2812991142272949 VAL: 0.29032179713249207
INFO:root:42
Train: 0.2818125784397125 VAL: 0.28847065567970276
INFO:root:43
Train: 0.28201642632484436 VAL: 0.28967079520225525
INFO:root:44
Train: 0.28137776255607605 VAL: 0.2890269160270691
INFO:root:45
Train: 0.2808693051338196 VAL: 0.28906866908073425
INFO:root:46
Train: 0.2806912064552307 VAL: 0.28976577520370483
INFO:root:47
Train: 0.28014039993286133 VAL: 0.2896624803543091
INFO:root:48
Train: 0.28012630343437195 VAL: 0.28917813301086426
INFO:root:49
Train: 0.2802809476852417 VAL: 0.2917795479297638
INFO:root:50
Train: 0.27944549918174744 VAL: 0.2926830053329468
INFO:root:51
Train: 0.27880507707595825 VAL: 0.29166972637176514
INFO:root:52
Train: 0.27958396077156067 VAL: 0.28903061151504517
INFO:root:53
Train: 0.27942344546318054 VAL: 0.2895906865596771
INFO:root:54
Train: 0.27718597650527954 VAL: 0.28950533270835876
INFO:root:55
Train: 0.2773246765136719 VAL: 0.2902604937553406
INFO:root:56
Train: 0.2771906554698944 VAL: 0.2888627052307129
INFO:root:57
Train: 0.2759539484977722 VAL: 0.2891227900981903
INFO:root:58
Train: 0.2767269015312195 VAL: 0.2898896634578705
INFO:root:59
Train: 0.27605050802230835 VAL: 0.28933051228523254
INFO:root:60
Train: 0.27561700344085693 VAL: 0.28926464915275574
INFO:root:61
Train: 0.27709758281707764 VAL: 0.29067957401275635
INFO:root:62
Train: 0.27632102370262146 VAL: 0.2900264859199524
INFO:root:63
Train: 0.2759207785129547 VAL: 0.2895587384700775
INFO:root:64
Train: 0.2762015163898468 VAL: 0.2903563678264618
INFO:root:65
Train: 0.2743036150932312 VAL: 0.2898426949977875
INFO:root:66
Train: 0.2742043435573578 VAL: 0.2897913455963135
INFO:root:67
Train: 0.2730768620967865 VAL: 0.29028111696243286
INFO:root:68
Train: 0.27408257126808167 VAL: 0.28969430923461914
INFO:root:69
Train: 0.27349773049354553 VAL: 0.29011866450309753
INFO:root:70
Train: 0.2733491063117981 VAL: 0.2897345721721649
INFO:root:71
Train: 0.2740149199962616 VAL: 0.28953954577445984
INFO:root:72
Train: 0.273573100566864 VAL: 0.2903352379798889
INFO:root:BEST VAL: 0.2903352379798889 TEST : 0.28856998682022095
