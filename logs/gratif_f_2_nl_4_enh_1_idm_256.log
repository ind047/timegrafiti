INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 23.22483253479004 VAL: 1.0691487789154053
INFO:root:2
Train: 0.7870096564292908 VAL: 0.5926833152770996
INFO:root:3
Train: 0.6087006330490112 VAL: 0.6535807847976685
INFO:root:4
Train: 0.5698472261428833 VAL: 0.4038224518299103
INFO:root:5
Train: 0.5226941704750061 VAL: 0.3150548040866852
INFO:root:6
Train: 0.50530606508255 VAL: 0.27593687176704407
INFO:root:7
Train: 0.4476149380207062 VAL: 0.34020763635635376
INFO:root:8
Train: 0.3476047217845917 VAL: 0.2832862436771393
INFO:root:9
Train: 0.3430815041065216 VAL: 0.26742327213287354
INFO:root:10
Train: 0.3475848436355591 VAL: 0.39133575558662415
INFO:root:11
Train: 0.3997633755207062 VAL: 0.27561014890670776
INFO:root:12
Train: 0.3634897768497467 VAL: 0.276123970746994
INFO:root:13
Train: 0.3714906871318817 VAL: 0.3385758101940155
INFO:root:14
Train: 0.3918319642543793 VAL: 0.3054019510746002
INFO:root:15
Train: 0.40216538310050964 VAL: 0.33390000462532043
INFO:root:16
Train: 0.3354813754558563 VAL: 0.31709617376327515
INFO:root:17
Train: 0.30302661657333374 VAL: 0.28346842527389526
INFO:root:18
Train: 0.31918129324913025 VAL: 0.28491687774658203
INFO:root:19
Train: 0.30767717957496643 VAL: 0.27341076731681824
INFO:root:20
Train: 0.3102743923664093 VAL: 0.2971378266811371
INFO:root:21
Train: 0.3069725036621094 VAL: 0.2921077311038971
INFO:root:22
Train: 0.28690841794013977 VAL: 0.2692127525806427
INFO:root:23
Train: 0.3026617467403412 VAL: 0.2801341712474823
INFO:root:24
Train: 0.29825541377067566 VAL: 0.30664926767349243
INFO:root:25
Train: 0.30297279357910156 VAL: 0.2755950093269348
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 10.034577369689941 VAL: 0.9100019931793213
INFO:root:2
Train: 0.9998112320899963 VAL: 0.6059443950653076
INFO:root:3
Train: 0.6729244589805603 VAL: 0.5360708236694336
INFO:root:4
Train: 0.5445101857185364 VAL: 0.44453489780426025
INFO:root:5
Train: 0.4934827387332916 VAL: 0.3438582420349121
INFO:root:6
Train: 0.4587613046169281 VAL: 0.28800666332244873
INFO:root:7
Train: 0.6103813648223877 VAL: 0.3655770719051361
INFO:root:8
Train: 0.44741129875183105 VAL: 0.33344969153404236
INFO:root:9
Train: 0.43169328570365906 VAL: 0.34865742921829224
INFO:root:10
Train: 0.3666926920413971 VAL: 0.29010820388793945
INFO:root:11
Train: 0.41229817271232605 VAL: 0.26117372512817383
INFO:root:12
Train: 0.4321138858795166 VAL: 0.260823130607605
INFO:root:13
Train: 0.403391569852829 VAL: 0.24995921552181244
INFO:root:14
Train: 0.4174604117870331 VAL: 0.24519146978855133
INFO:root:15
Train: 0.41494736075401306 VAL: 0.27284154295921326
INFO:root:16
Train: 0.4015953838825226 VAL: 0.26923662424087524
INFO:root:17
Train: 0.34611478447914124 VAL: 0.41248685121536255
INFO:root:18
Train: 0.349118709564209 VAL: 0.2523338198661804
INFO:root:19
Train: 0.3512740433216095 VAL: 0.24053318798542023
INFO:root:20
Train: 0.3562968671321869 VAL: 0.2596161365509033
INFO:root:21
Train: 0.40120336413383484 VAL: 0.25172799825668335
INFO:root:22
Train: 0.3624964952468872 VAL: 0.7876030206680298
INFO:root:23
Train: 0.3380891978740692 VAL: 0.2620429992675781
INFO:root:24
Train: 0.348147988319397 VAL: 0.24248887598514557
INFO:root:25
Train: 0.3187110126018524 VAL: 0.24355357885360718
INFO:root:26
Train: 0.30611029267311096 VAL: 0.2725119888782501
INFO:root:27
Train: 0.34856119751930237 VAL: 0.23110784590244293
INFO:root:28
Train: 0.3477020263671875 VAL: 0.23271353542804718
INFO:root:29
Train: 0.3210074007511139 VAL: 0.23594295978546143
INFO:root:30
Train: 0.3235829174518585 VAL: 0.24986231327056885
INFO:root:31
Train: 0.3140653967857361 VAL: 0.2712397277355194
INFO:root:32
Train: 0.3170064389705658 VAL: 0.2528420090675354
INFO:root:33
Train: 0.30485132336616516 VAL: 0.2417488992214203
INFO:root:34
Train: 0.29455456137657166 VAL: 0.2399529218673706
INFO:root:35
Train: 0.3088456392288208 VAL: 0.25914859771728516
INFO:root:36
Train: 0.3038218021392822 VAL: 0.2736997604370117
INFO:root:37
Train: 0.31038546562194824 VAL: 0.2685376703739166
INFO:root:38
Train: 0.3067173659801483 VAL: 0.259813129901886
INFO:root:39
Train: 0.299468457698822 VAL: 0.24657204747200012
INFO:root:40
Train: 0.30156517028808594 VAL: 0.26292863488197327
INFO:root:41
Train: 0.3040653169155121 VAL: 0.2390001118183136
INFO:root:42
Train: 0.3002174198627472 VAL: 0.2439597100019455
INFO:root:43
Train: 0.3028482496738434 VAL: 0.26176124811172485
INFO:root:44
Train: 0.2756686508655548 VAL: 0.2417541742324829
INFO:root:45
Train: 0.2981890141963959 VAL: 0.25993677973747253
INFO:root:46
Train: 0.29686781764030457 VAL: 0.24464905261993408
INFO:root:47
Train: 0.27132323384284973 VAL: 0.25567689538002014
INFO:root:48
Train: 0.28404995799064636 VAL: 0.24747976660728455
INFO:root:49
Train: 0.30059194564819336 VAL: 0.2572501003742218
INFO:root:50
Train: 0.2711378037929535 VAL: 0.24178779125213623
INFO:root:51
Train: 0.30125415325164795 VAL: 0.2548277974128723
INFO:root:52
Train: 0.2910510301589966 VAL: 0.25026270747184753
INFO:root:53
Train: 0.29414165019989014 VAL: 0.25557181239128113
INFO:root:54
Train: 0.2979448139667511 VAL: 0.24580299854278564
INFO:root:55
Train: 0.29386356472969055 VAL: 0.2511814832687378
INFO:root:56
Train: 0.2946750223636627 VAL: 0.2620011568069458
INFO:root:57
Train: 0.27901628613471985 VAL: 0.2531350255012512
INFO:root:BEST VAL: 0.2531350255012512 TEST : 0.33317193388938904
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 12.097952842712402 VAL: 1.0142170190811157
INFO:root:2
Train: 0.7378910183906555 VAL: 0.5378988981246948
INFO:root:3
Train: 0.6433711051940918 VAL: 0.6259215474128723
INFO:root:4
Train: 0.4814487397670746 VAL: 0.42885977029800415
INFO:root:5
Train: 0.38630667328834534 VAL: 0.354248046875
INFO:root:6
Train: 0.3623110353946686 VAL: 0.32802948355674744
INFO:root:7
Train: 0.364141583442688 VAL: 0.3166547417640686
INFO:root:8
Train: 0.44105827808380127 VAL: 0.42796382308006287
INFO:root:9
Train: 0.3421236276626587 VAL: 0.30399349331855774
INFO:root:10
Train: 0.4387446343898773 VAL: 0.3536771237850189
INFO:root:11
Train: 0.38608646392822266 VAL: 0.3396269679069519
INFO:root:12
Train: 0.36607322096824646 VAL: 0.29207852482795715
INFO:root:13
Train: 0.34874042868614197 VAL: 0.27696388959884644
INFO:root:14
Train: 0.31955665349960327 VAL: 0.30226242542266846
INFO:root:15
Train: 0.3051736652851105 VAL: 0.3060273826122284
INFO:root:16
Train: 0.31483107805252075 VAL: 0.2978594899177551
INFO:root:17
Train: 0.31607505679130554 VAL: 0.3034331202507019
INFO:root:18
Train: 0.3101148307323456 VAL: 0.3132886290550232
INFO:root:19
Train: 0.3095390200614929 VAL: 0.2663094401359558
INFO:root:20
Train: 0.29566121101379395 VAL: 0.2870512008666992
INFO:root:21
Train: 0.3028436601161957 VAL: 0.27622079849243164
INFO:root:22
Train: 0.30561578273773193 VAL: 0.2795766592025757
INFO:root:23
Train: 0.29685264825820923 VAL: 0.29220885038375854
INFO:root:24
Train: 0.27603569626808167 VAL: 0.2947775721549988
INFO:root:25
Train: 0.2762005031108856 VAL: 0.2775864899158478
INFO:root:26
Train: 0.2999045252799988 VAL: 0.2770256996154785
INFO:root:27
Train: 0.29565635323524475 VAL: 0.2880623936653137
INFO:root:28
Train: 0.30477139353752136 VAL: 0.288176566362381
INFO:root:29
Train: 0.2926764190196991 VAL: 0.271101713180542
INFO:root:30
Train: 0.29713505506515503 VAL: 0.2760460376739502
INFO:root:31
Train: 0.2934779226779938 VAL: 0.3020131587982178
INFO:root:32
Train: 0.2874235212802887 VAL: 0.27825430035591125
INFO:root:33
Train: 0.29600790143013 VAL: 0.28367990255355835
INFO:root:34
Train: 0.29750165343284607 VAL: 0.2833075225353241
INFO:root:35
Train: 0.27597835659980774 VAL: 0.2826600670814514
INFO:root:36
Train: 0.29323244094848633 VAL: 0.287177175283432
INFO:root:37
Train: 0.29242944717407227 VAL: 0.2834603786468506
INFO:root:38
Train: 0.2896851897239685 VAL: 0.27887415885925293
INFO:root:39
Train: 0.2761119306087494 VAL: 0.28716689348220825
INFO:root:40
Train: 0.28920790553092957 VAL: 0.28479263186454773
INFO:root:41
Train: 0.28957870602607727 VAL: 0.28124502301216125
INFO:root:42
Train: 0.29345837235450745 VAL: 0.2808559536933899
INFO:root:43
Train: 0.2940691411495209 VAL: 0.28566697239875793
INFO:root:44
Train: 0.28601762652397156 VAL: 0.2813989222049713
INFO:root:45
Train: 0.2762843072414398 VAL: 0.2869880199432373
INFO:root:46
Train: 0.28971314430236816 VAL: 0.2867744565010071
INFO:root:47
Train: 0.2888445556163788 VAL: 0.28615790605545044
INFO:root:48
Train: 0.2909175455570221 VAL: 0.2867264747619629
INFO:root:49
Train: 0.2909540832042694 VAL: 0.2847858667373657
INFO:root:BEST VAL: 0.2847858667373657 TEST : 0.3449765145778656
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.805671215057373 VAL: 0.5224443674087524
INFO:root:2
Train: 0.9672520160675049 VAL: 16.02666473388672
INFO:root:3
Train: 44529900.0 VAL: 16763.59375
INFO:root:4
Train: 4109.56591796875 VAL: 1582.921630859375
INFO:root:5
Train: 1205.5614013671875 VAL: 537.4517822265625
INFO:root:6
Train: 884.69677734375 VAL: 613.5436401367188
INFO:root:7
Train: 844.7192993164062 VAL: 3729.51025390625
INFO:root:8
Train: 868.0398559570312 VAL: 471.43048095703125
INFO:root:9
Train: 493.4252624511719 VAL: 1201.7454833984375
INFO:root:10
Train: 798677467136.0 VAL: 3633742592.0
INFO:root:11
Train: 2787015936.0 VAL: 138405824.0
INFO:root:12
Train: 127025032.0 VAL: 71465488.0
INFO:root:13
Train: 74740832.0 VAL: 50097504.0
INFO:root:14
Train: 59796348.0 VAL: 77249872.0
INFO:root:15
Train: 43933164.0 VAL: 39292020.0
INFO:root:16
Train: 197602816.0 VAL: 136723456.0
INFO:root:17
Train: 78872344.0 VAL: 39511864.0
INFO:root:18
Train: 282751500288.0 VAL: 13602233344.0
INFO:root:19
Train: 845558592.0 VAL: 192174096.0
INFO:root:20
Train: 1306533298176.0 VAL: 42291208192.0
INFO:root:21
Train: 1908174720.0 VAL: 70147056.0
INFO:root:22
Train: 278143991808.0 VAL: 560176693248.0
INFO:root:23
Train: 74279960576.0 VAL: 17482899456.0
INFO:root:24
Train: 13695960064.0 VAL: 7740067328.0
INFO:root:25
Train: 68087214080.0 VAL: 27072937984.0
INFO:root:26
Train: 110559232000.0 VAL: 29460287488.0
INFO:root:27
Train: 14473384960.0 VAL: 11373508608.0
INFO:root:28
Train: 7421035008.0 VAL: 4736107520.0
INFO:root:29
Train: 10721507328.0 VAL: 2551367680.0
INFO:root:30
Train: 9101285376.0 VAL: 36247576576.0
INFO:root:31
Train: 11666274304.0 VAL: 1854106880.0
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.7497851252555847 VAL: 0.5125045776367188
INFO:root:2
Train: 0.4420623183250427 VAL: 0.4983357787132263
INFO:root:3
Train: 220035920.0 VAL: 3029353.5
INFO:root:4
Train: 146691.84375 VAL: 14554.451171875
INFO:root:5
Train: 20982.458984375 VAL: 14197.447265625
INFO:root:6
Train: 6310.34228515625 VAL: 3266.8828125
INFO:root:7
Train: 3743.587890625 VAL: 4315.208984375
INFO:root:8
Train: 2920.851806640625 VAL: 9135.96875
INFO:root:9
Train: 4674.68310546875 VAL: 2613.67529296875
INFO:root:10
Train: 3808.90380859375 VAL: 5599.9501953125
INFO:root:11
Train: 8267842560.0 VAL: 1215716480.0
INFO:root:12
Train: 6202759168.0 VAL: 18791328.0
INFO:root:13
Train: 4452541.5 VAL: 2996145.0
INFO:root:14
Train: 2255847.25 VAL: 2208302.5
INFO:root:15
Train: 1644924.25 VAL: 1562628.25
INFO:root:16
Train: 1705010.125 VAL: 1760358.625
INFO:root:17
Train: 1479152.625 VAL: 1515941.0
INFO:root:18
Train: 1098722.25 VAL: 997523.1875
INFO:root:19
Train: 845059.8125 VAL: 857239.6875
INFO:root:20
Train: 717753.0 VAL: 709691.5625
INFO:root:21
Train: 598601.4375 VAL: 557672.75
INFO:root:22
Train: 482350.46875 VAL: 454497.875
INFO:root:23
Train: 420020.375 VAL: 379419.21875
INFO:root:24
Train: 2263629.75 VAL: 2003923.0
INFO:root:25
Train: 1266603.5 VAL: 847082.375
INFO:root:26
Train: 939421.75 VAL: 619107.0625
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='mimiciv')
INFO:root:{'input_dim': 100, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.580978512763977 VAL: 0.30103030800819397
INFO:root:2
Train: 0.28557413816452026 VAL: 0.26948195695877075
INFO:root:3
Train: 0.2690669596195221 VAL: 0.2738257646560669
INFO:root:4
Train: 0.26415154337882996 VAL: 0.30394524335861206
INFO:root:5
Train: 0.25809675455093384 VAL: 0.26674020290374756
INFO:root:6
Train: 0.2519232928752899 VAL: 0.25213372707366943
INFO:root:7
Train: 0.24811901152133942 VAL: 0.2493639588356018
INFO:root:8
Train: 0.24555803835391998 VAL: 0.24693866074085236
INFO:root:9
Train: 0.24139752984046936 VAL: 0.24526093900203705
INFO:root:10
Train: 0.23993724584579468 VAL: 0.24607782065868378
INFO:root:11
Train: 0.23929563164710999 VAL: 0.25002139806747437
INFO:root:12
Train: 0.2347410023212433 VAL: 0.24270093441009521
INFO:root:13
Train: 0.2348240464925766 VAL: 0.2408415526151657
INFO:root:14
Train: 0.23233415186405182 VAL: 0.23758772015571594
INFO:root:15
Train: 0.2285773605108261 VAL: 0.24665427207946777
INFO:root:16
Train: 0.22773554921150208 VAL: 0.23508942127227783
INFO:root:17
Train: 0.22553923726081848 VAL: 0.23446838557720184
INFO:root:18
Train: 0.22583651542663574 VAL: 0.23659692704677582
INFO:root:19
Train: 0.22440309822559357 VAL: 0.24879157543182373
INFO:root:20
Train: 0.2238212674856186 VAL: 0.23076125979423523
INFO:root:21
Train: 0.2247573882341385 VAL: 0.23718634247779846
INFO:root:22
Train: 0.2216850370168686 VAL: 0.2363031506538391
INFO:root:23
Train: 0.2288711816072464 VAL: 0.23632456362247467
INFO:root:24
Train: 4913985.5 VAL: 2609256.5
INFO:root:25
Train: 172113231872.0 VAL: 76918448.0
INFO:root:26
Train: 95139408.0 VAL: 87798848.0
INFO:root:27
Train: 24586762.0 VAL: 13605557.0
INFO:root:28
Train: 50181369856.0 VAL: 90224576.0
INFO:root:29
Train: 1091925245952.0 VAL: 416701920.0
INFO:root:30
Train: 163039184.0 VAL: 77344640.0
INFO:root:31
Train: 79427272.0 VAL: 60244084.0
INFO:root:32
Train: 58188112.0 VAL: 47578520.0
INFO:root:33
Train: 51803196.0 VAL: 42184896.0
INFO:root:34
Train: 45831316.0 VAL: 43769528.0
INFO:root:35
Train: 6210262016.0 VAL: 17832634368.0
INFO:root:36
Train: 3715707648.0 VAL: 1140318464.0
INFO:root:37
Train: 1512608384.0 VAL: 458397792.0
INFO:root:38
Train: 484470560.0 VAL: 224003520.0
INFO:root:39
Train: 206281216.0 VAL: 129760744.0
INFO:root:40
Train: 139214384.0 VAL: 103511040.0
INFO:root:41
Train: 105598752.0 VAL: 107434352.0
INFO:root:42
Train: 87207656.0 VAL: 100363456.0
INFO:root:43
Train: 73253360.0 VAL: 99605032.0
INFO:root:44
Train: 63860328.0 VAL: 58736624.0
INFO:root:45
Train: 55653480.0 VAL: 53707604.0
INFO:root:46
Train: 14605850624.0 VAL: 1858489728.0
INFO:root:47
Train: 1485491328.0 VAL: 2073984000.0
INFO:root:48
Train: 1102500224.0 VAL: 500858016.0
INFO:root:49
Train: 1513633280.0 VAL: 858184448.0
INFO:root:50
Train: 534204192.0 VAL: 334747776.0
INFO:root:BEST VAL: 334747776.0 TEST : 0.22818726301193237
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 1.6860673427581787 VAL: 0.36128365993499756
INFO:root:2
Train: 0.3286413848400116 VAL: 0.3164069950580597
INFO:root:3
Train: 0.31194785237312317 VAL: 0.31589436531066895
INFO:root:4
Train: 0.30183693766593933 VAL: 0.29963862895965576
INFO:root:5
Train: 0.30427879095077515 VAL: 0.31207072734832764
INFO:root:6
Train: 0.300808846950531 VAL: 0.2942931354045868
INFO:root:7
Train: 0.29910317063331604 VAL: 0.2950226664543152
INFO:root:8
Train: 0.29683905839920044 VAL: 0.3001455068588257
INFO:root:9
Train: 0.29774656891822815 VAL: 0.2909505367279053
INFO:root:10
Train: 0.29411545395851135 VAL: 0.29561060667037964
INFO:root:11
Train: 0.2959658205509186 VAL: 0.29099562764167786
INFO:root:12
Train: 0.2936125695705414 VAL: 0.29363057017326355
INFO:root:13
Train: 0.2943899631500244 VAL: 0.3035850524902344
INFO:root:14
Train: 0.2931234538555145 VAL: 0.29450148344039917
INFO:root:15
Train: 0.2924697995185852 VAL: 0.2930377125740051
INFO:root:16
Train: 0.2928578853607178 VAL: 0.2887992858886719
INFO:root:17
Train: 0.2901949882507324 VAL: 0.2894003391265869
INFO:root:18
Train: 0.2898273766040802 VAL: 0.2877737283706665
INFO:root:19
Train: 0.2900683879852295 VAL: 0.2894849479198456
INFO:root:20
Train: 0.28890249133110046 VAL: 0.2897898554801941
INFO:root:21
Train: 0.2883404493331909 VAL: 0.2870274782180786
INFO:root:22
Train: 0.28798750042915344 VAL: 0.28781038522720337
INFO:root:23
Train: 0.2876122295856476 VAL: 0.29068028926849365
INFO:root:24
Train: 0.2871588170528412 VAL: 0.28750014305114746
INFO:root:25
Train: 0.28611984848976135 VAL: 0.2897389233112335
INFO:root:26
Train: 0.2869819700717926 VAL: 0.2878105640411377
INFO:root:27
Train: 0.2874068319797516 VAL: 0.2892266809940338
INFO:root:28
Train: 0.28601619601249695 VAL: 0.28615665435791016
INFO:root:29
Train: 0.28538501262664795 VAL: 0.28882086277008057
INFO:root:30
Train: 0.2858021855354309 VAL: 0.2900964021682739
INFO:root:31
Train: 0.28574293851852417 VAL: 0.29015296697616577
INFO:root:32
Train: 0.2841086685657501 VAL: 0.2877993583679199
INFO:root:33
Train: 0.28236496448516846 VAL: 0.28917938470840454
INFO:root:34
Train: 0.2835792899131775 VAL: 0.28937456011772156
INFO:root:35
Train: 0.2831099331378937 VAL: 0.28688281774520874
INFO:root:36
Train: 0.28051164746284485 VAL: 0.2859949469566345
INFO:root:37
Train: 0.28262758255004883 VAL: 0.2889559268951416
INFO:root:38
Train: 0.2814110517501831 VAL: 0.289096862077713
INFO:root:39
Train: 0.28037533164024353 VAL: 0.29184669256210327
INFO:root:40
Train: 0.27897799015045166 VAL: 0.2875595688819885
INFO:root:41
Train: 0.27757441997528076 VAL: 0.29104381799697876
INFO:root:42
Train: 0.27682217955589294 VAL: 0.29075342416763306
INFO:root:43
Train: 0.27616849541664124 VAL: 0.28942567110061646
INFO:root:44
Train: 0.2769679129123688 VAL: 0.29199349880218506
INFO:root:45
Train: 0.27668604254722595 VAL: 0.30281782150268555
INFO:root:46
Train: 0.27662914991378784 VAL: 0.28847169876098633
INFO:root:47
Train: 0.27385976910591125 VAL: 0.28833937644958496
INFO:root:48
Train: 0.26658985018730164 VAL: 0.28981447219848633
INFO:root:49
Train: 0.2634607255458832 VAL: 0.29379644989967346
INFO:root:50
Train: 0.2612057030200958 VAL: 0.29576680064201355
INFO:root:51
Train: 0.26016438007354736 VAL: 0.2951602339744568
INFO:root:52
Train: 0.2585645616054535 VAL: 0.2946813702583313
INFO:root:53
Train: 0.25649601221084595 VAL: 0.29490411281585693
INFO:root:54
Train: 0.25673213601112366 VAL: 0.2937929034233093
INFO:root:55
Train: 0.25268468260765076 VAL: 0.29097360372543335
INFO:root:56
Train: 0.2510890066623688 VAL: 0.2988486886024475
INFO:root:57
Train: 0.25053730607032776 VAL: 0.2986598312854767
INFO:root:58
Train: 0.251800000667572 VAL: 0.29370713233947754
INFO:root:59
Train: 0.23974841833114624 VAL: 0.2988486886024475
INFO:root:60
Train: 0.23350150883197784 VAL: 0.3002490997314453
INFO:root:61
Train: 0.23111523687839508 VAL: 0.3058244287967682
INFO:root:62
Train: 0.22847430408000946 VAL: 0.30629611015319824
INFO:root:63
Train: 0.22557559609413147 VAL: 0.30202630162239075
INFO:root:64
Train: 0.22620901465415955 VAL: 0.30702999234199524
INFO:root:65
Train: 0.22410495579242706 VAL: 0.30855268239974976
INFO:root:66
Train: 0.21825011074543 VAL: 0.31285908818244934
INFO:root:BEST VAL: 0.31285908818244934 TEST : 0.2877051830291748
