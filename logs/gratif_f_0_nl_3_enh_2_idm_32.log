INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.7213719487190247 VAL: 0.7891080975532532
INFO:root:2
Train: 0.6015850305557251 VAL: 0.6619837284088135
INFO:root:3
Train: 0.5395283699035645 VAL: 0.5250656604766846
INFO:root:4
Train: 0.46744105219841003 VAL: 0.4112696051597595
INFO:root:5
Train: 0.37610962986946106 VAL: 0.7415299415588379
INFO:root:6
Train: 0.3487984240055084 VAL: 0.8091382384300232
INFO:root:7
Train: 0.31762048602104187 VAL: 0.3427309989929199
INFO:root:8
Train: 0.331775039434433 VAL: 0.49814915657043457
INFO:root:9
Train: 0.28289273381233215 VAL: 0.7914078235626221
INFO:root:10
Train: 0.32002490758895874 VAL: 0.5690841674804688
INFO:root:11
Train: 0.3116544783115387 VAL: 0.43089982867240906
INFO:root:12
Train: 0.3167476952075958 VAL: 0.4940706789493561
INFO:root:13
Train: 0.30873164534568787 VAL: 0.5242844820022583
INFO:root:14
Train: 0.2926088869571686 VAL: 0.4545060396194458
INFO:root:15
Train: 0.31232982873916626 VAL: 0.4362128674983978
INFO:root:16
Train: 0.3062504231929779 VAL: 0.5032459497451782
INFO:root:17
Train: 0.30506646633148193 VAL: 0.4908651113510132
INFO:root:18
Train: 0.3069656491279602 VAL: 0.4562685489654541
INFO:root:19
Train: 0.30325210094451904 VAL: 0.4372114837169647
INFO:root:20
Train: 0.30931901931762695 VAL: 0.4110569655895233
INFO:root:21
Train: 0.2974688410758972 VAL: 0.4108186960220337
INFO:root:22
Train: 0.2915807366371155 VAL: 0.4353489279747009
INFO:root:23
Train: 0.3056087791919708 VAL: 0.42146727442741394
INFO:root:24
Train: 0.3087198734283447 VAL: 0.4108160436153412
INFO:root:25
Train: 0.30844977498054504 VAL: 0.4230444133281708
INFO:root:26
Train: 0.3055054843425751 VAL: 0.3821626305580139
INFO:root:27
Train: 0.3100147843360901 VAL: 0.37553220987319946
INFO:root:28
Train: 0.3005792498588562 VAL: 0.3853638172149658
INFO:root:29
Train: 0.30371174216270447 VAL: 0.3847656548023224
INFO:root:30
Train: 0.3052920997142792 VAL: 0.37531766295433044
INFO:root:31
Train: 0.2837863862514496 VAL: 0.3692888617515564
INFO:root:32
Train: 0.3002137541770935 VAL: 0.3853300213813782
INFO:root:33
Train: 0.2997485101222992 VAL: 0.39361241459846497
INFO:root:34
Train: 0.2860136926174164 VAL: 0.37845996022224426
INFO:root:35
Train: 0.2762620151042938 VAL: 0.37500256299972534
INFO:root:36
Train: 0.3018094301223755 VAL: 0.39416348934173584
INFO:root:37
Train: 0.3039450943470001 VAL: 0.40774068236351013
INFO:root:BEST VAL: 0.40774068236351013 TEST : 0.20994868874549866
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.46932145953178406 VAL: 0.3869015574455261
INFO:root:2
Train: 0.38515737652778625 VAL: 0.38048219680786133
INFO:root:3
Train: 0.33952417969703674 VAL: 0.3096846044063568
INFO:root:4
Train: 0.30654093623161316 VAL: 0.296583890914917
INFO:root:5
Train: 0.3037356436252594 VAL: 0.29824763536453247
INFO:root:6
Train: 0.298424631357193 VAL: 0.29456833004951477
INFO:root:7
Train: 0.2985415756702423 VAL: 0.29711607098579407
INFO:root:8
Train: 0.296661376953125 VAL: 0.29283589124679565
INFO:root:9
Train: 0.2959318459033966 VAL: 0.2924278676509857
INFO:root:10
Train: 0.2945800721645355 VAL: 0.297343909740448
INFO:root:11
Train: 0.295186847448349 VAL: 0.2930762767791748
INFO:root:12
Train: 0.29252198338508606 VAL: 0.29213747382164
INFO:root:13
Train: 0.29497817158699036 VAL: 0.2899375557899475
INFO:root:14
Train: 0.29379934072494507 VAL: 0.2930033802986145
INFO:root:15
Train: 0.29198238253593445 VAL: 0.2949846088886261
INFO:root:16
Train: 0.2916542887687683 VAL: 0.2895463705062866
INFO:root:17
Train: 0.28965210914611816 VAL: 0.2922331690788269
INFO:root:18
Train: 0.2902223467826843 VAL: 0.29345497488975525
INFO:root:19
Train: 0.2909586429595947 VAL: 0.28936541080474854
INFO:root:20
Train: 0.28915783762931824 VAL: 0.2892749309539795
INFO:root:21
Train: 0.2890808582305908 VAL: 0.2916414141654968
INFO:root:22
Train: 0.2883159816265106 VAL: 0.2896572947502136
INFO:root:23
Train: 0.28918519616127014 VAL: 0.2935481369495392
INFO:root:24
Train: 0.28853896260261536 VAL: 0.28825491666793823
INFO:root:25
Train: 0.28875455260276794 VAL: 0.28728172183036804
INFO:root:26
Train: 0.28751036524772644 VAL: 0.28799936175346375
INFO:root:27
Train: 0.2868403494358063 VAL: 0.2892047166824341
INFO:root:28
Train: 0.2864229381084442 VAL: 0.2921452224254608
INFO:root:29
Train: 0.28718772530555725 VAL: 0.2895328402519226
INFO:root:30
Train: 0.28601109981536865 VAL: 0.29205507040023804
INFO:root:31
Train: 0.28684473037719727 VAL: 0.29405492544174194
INFO:root:32
Train: 0.2852005958557129 VAL: 0.287418007850647
INFO:root:33
Train: 0.2851478159427643 VAL: 0.2883715033531189
INFO:root:34
Train: 0.2857222259044647 VAL: 0.2870333194732666
INFO:root:35
Train: 0.2850674092769623 VAL: 0.291157066822052
INFO:root:36
Train: 0.2845207750797272 VAL: 0.28734779357910156
INFO:root:37
Train: 0.28486189246177673 VAL: 0.28769999742507935
INFO:root:38
Train: 0.28387755155563354 VAL: 0.288636714220047
INFO:root:39
Train: 0.28525683283805847 VAL: 0.28671136498451233
INFO:root:40
Train: 0.28414925932884216 VAL: 0.289930522441864
INFO:root:41
Train: 0.2828661799430847 VAL: 0.2885589003562927
INFO:root:42
Train: 0.282405287027359 VAL: 0.28773000836372375
INFO:root:43
Train: 0.28255051374435425 VAL: 0.2861652374267578
INFO:root:44
Train: 0.28058159351348877 VAL: 0.28539425134658813
INFO:root:45
Train: 0.282277375459671 VAL: 0.29057374596595764
INFO:root:46
Train: 0.2813494801521301 VAL: 0.2899974584579468
INFO:root:47
Train: 0.28098371624946594 VAL: 0.28861314058303833
INFO:root:48
Train: 0.27977800369262695 VAL: 0.28752681612968445
INFO:root:49
Train: 0.2822217643260956 VAL: 0.2880190312862396
INFO:root:50
Train: 0.281514048576355 VAL: 0.29002293944358826
INFO:root:51
Train: 0.28126683831214905 VAL: 0.28819721937179565
INFO:root:52
Train: 0.2803979218006134 VAL: 0.29052358865737915
INFO:root:53
Train: 0.27988559007644653 VAL: 0.2874094843864441
INFO:root:54
Train: 0.27710363268852234 VAL: 0.2864246368408203
INFO:root:55
Train: 0.279387503862381 VAL: 0.2903960049152374
INFO:root:56
Train: 0.2758691608905792 VAL: 0.28710877895355225
INFO:root:57
Train: 0.27383169531822205 VAL: 0.2866501212120056
INFO:root:58
Train: 0.2745855152606964 VAL: 0.28616365790367126
INFO:root:59
Train: 0.2729954123497009 VAL: 0.28737419843673706
INFO:root:60
Train: 0.27360662817955017 VAL: 0.285616934299469
INFO:root:61
Train: 0.27219775319099426 VAL: 0.28677940368652344
INFO:root:62
Train: 0.2718050479888916 VAL: 0.2865666151046753
INFO:root:63
Train: 0.27150580286979675 VAL: 0.29010170698165894
INFO:root:64
Train: 0.27137991786003113 VAL: 0.2886982560157776
INFO:root:65
Train: 0.27138862013816833 VAL: 0.28669244050979614
INFO:root:66
Train: 0.2710902690887451 VAL: 0.2864932417869568
INFO:root:67
Train: 0.26859307289123535 VAL: 0.28665590286254883
INFO:root:68
Train: 0.2685895264148712 VAL: 0.2871292233467102
INFO:root:69
Train: 0.2675594687461853 VAL: 0.2865322232246399
INFO:root:70
Train: 0.26760199666023254 VAL: 0.2872295379638672
INFO:root:71
Train: 0.2675071656703949 VAL: 0.2898104786872864
INFO:root:72
Train: 0.26655077934265137 VAL: 0.2875918447971344
INFO:root:73
Train: 0.2664456069469452 VAL: 0.2882496416568756
INFO:root:74
Train: 0.26651355624198914 VAL: 0.2867399752140045
INFO:root:BEST VAL: 0.2867399752140045 TEST : 0.28738972544670105
