INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 6.8028788566589355 VAL: 1.0840725898742676
INFO:root:2
Train: 0.9075760841369629 VAL: 0.47134268283843994
INFO:root:3
Train: 0.5673097968101501 VAL: 0.43875211477279663
INFO:root:4
Train: 0.43306636810302734 VAL: 0.30531132221221924
INFO:root:5
Train: 0.39516887068748474 VAL: 0.26940929889678955
INFO:root:6
Train: 0.36925265192985535 VAL: 0.2687470614910126
INFO:root:7
Train: 0.4749266803264618 VAL: 0.2539101839065552
INFO:root:8
Train: 0.4144320487976074 VAL: 0.289412260055542
INFO:root:9
Train: 0.3774832487106323 VAL: 0.2541321814060211
INFO:root:10
Train: 0.33028116822242737 VAL: 0.3335932493209839
INFO:root:11
Train: 0.3213235139846802 VAL: 0.28278791904449463
INFO:root:12
Train: 0.31104323267936707 VAL: 0.2749280035495758
INFO:root:13
Train: 0.3016612231731415 VAL: 0.296877384185791
INFO:root:14
Train: 0.31282272934913635 VAL: 0.27997028827667236
INFO:root:15
Train: 0.3106522858142853 VAL: 0.24483439326286316
INFO:root:16
Train: 0.30561548471450806 VAL: 0.31649279594421387
INFO:root:17
Train: 0.3437851667404175 VAL: 0.2859712541103363
INFO:root:18
Train: 0.3744610846042633 VAL: 0.26895320415496826
INFO:root:19
Train: 0.32337239384651184 VAL: 0.34995195269584656
INFO:root:20
Train: 0.3298484683036804 VAL: 0.3342289328575134
INFO:root:21
Train: 0.2975917458534241 VAL: 0.2739485502243042
INFO:root:22
Train: 0.30284780263900757 VAL: 0.2977431118488312
INFO:root:23
Train: 0.3045421540737152 VAL: 0.327018141746521
INFO:root:24
Train: 0.308840274810791 VAL: 0.27991101145744324
INFO:root:25
Train: 0.2841157615184784 VAL: 0.3165774345397949
INFO:root:26
Train: 0.2882109582424164 VAL: 0.30710723996162415
INFO:root:27
Train: 0.3051822781562805 VAL: 0.26980718970298767
INFO:root:28
Train: 0.29138538241386414 VAL: 0.2999987006187439
INFO:root:29
Train: 0.2871728539466858 VAL: 0.29053109884262085
INFO:root:30
Train: 0.3026191294193268 VAL: 0.29847458004951477
INFO:root:31
Train: 0.3014642298221588 VAL: 0.29391130805015564
INFO:root:32
Train: 0.29700204730033875 VAL: 0.3019058406352997
INFO:root:33
Train: 0.2908036410808563 VAL: 0.29005512595176697
INFO:root:34
Train: 0.29774805903434753 VAL: 0.2802167534828186
INFO:root:35
Train: 0.30995461344718933 VAL: 0.3049185574054718
INFO:root:36
Train: 0.30425629019737244 VAL: 0.2998594343662262
INFO:root:37
Train: 0.2883487045764923 VAL: 0.3232239782810211
INFO:root:38
Train: 0.29639026522636414 VAL: 0.2958269417285919
INFO:root:39
Train: 0.29187440872192383 VAL: 0.2927655279636383
INFO:root:40
Train: 0.2851109802722931 VAL: 0.2975286543369293
INFO:root:41
Train: 0.294284850358963 VAL: 0.30407705903053284
INFO:root:42
Train: 0.2864879071712494 VAL: 0.29457733035087585
INFO:root:43
Train: 0.2955199182033539 VAL: 0.2949169874191284
INFO:root:44
Train: 0.28829628229141235 VAL: 0.3057243227958679
INFO:root:45
Train: 0.29102253913879395 VAL: 0.2994731366634369
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 9.117435455322266 VAL: 0.8796401023864746
INFO:root:2
Train: 0.7514998316764832 VAL: 0.5754297971725464
INFO:root:3
Train: 0.6796767711639404 VAL: 0.5305437445640564
INFO:root:4
Train: 0.5478124022483826 VAL: 0.40039610862731934
INFO:root:5
Train: 0.5477941036224365 VAL: 0.3548567295074463
INFO:root:6
Train: 0.4916657507419586 VAL: 0.30641409754753113
INFO:root:7
Train: 0.5244551301002502 VAL: 0.6350091695785522
INFO:root:8
Train: 0.5260776877403259 VAL: 0.318694531917572
INFO:root:9
Train: 0.4159027338027954 VAL: 0.3225190043449402
INFO:root:10
Train: 0.38729938864707947 VAL: 0.3158447742462158
INFO:root:11
Train: 0.3475942313671112 VAL: 0.5696892738342285
INFO:root:12
Train: 0.4460867941379547 VAL: 0.3810206949710846
INFO:root:13
Train: 0.42903372645378113 VAL: 0.27733683586120605
INFO:root:14
Train: 0.47299110889434814 VAL: 0.4357375502586365
INFO:root:15
Train: 0.4605541229248047 VAL: 0.3070821762084961
INFO:root:16
Train: 0.42032894492149353 VAL: 0.38378918170928955
INFO:root:17
Train: 0.3295226991176605 VAL: 0.4373553991317749
INFO:root:18
Train: 0.39183878898620605 VAL: 0.2800672650337219
INFO:root:19
Train: 0.33150073885917664 VAL: 0.24885742366313934
INFO:root:20
Train: 0.391833633184433 VAL: 0.2676263451576233
INFO:root:21
Train: 0.3289896249771118 VAL: 0.3842732012271881
INFO:root:22
Train: 0.3201821446418762 VAL: 0.3210965692996979
INFO:root:23
Train: 0.28583747148513794 VAL: 0.3026823103427887
INFO:root:24
Train: 0.30457380414009094 VAL: 0.3068850040435791
INFO:root:25
Train: 0.3059001863002777 VAL: 0.30472007393836975
INFO:root:26
Train: 0.3228989541530609 VAL: 0.341905415058136
INFO:root:27
Train: 0.3246566355228424 VAL: 0.2972252666950226
INFO:root:28
Train: 0.3162540793418884 VAL: 0.31228911876678467
INFO:root:29
Train: 0.29352033138275146 VAL: 0.33989211916923523
INFO:root:30
Train: 0.3043317496776581 VAL: 0.28915438055992126
INFO:root:31
Train: 0.3051113486289978 VAL: 0.2801744043827057
INFO:root:32
Train: 0.3037950098514557 VAL: 0.29038047790527344
INFO:root:33
Train: 0.30362290143966675 VAL: 0.3228578269481659
INFO:root:34
Train: 0.304264098405838 VAL: 0.3075851798057556
INFO:root:35
Train: 0.29799413681030273 VAL: 0.29940009117126465
INFO:root:36
Train: 0.3018374741077423 VAL: 0.2994947135448456
INFO:root:37
Train: 0.30395931005477905 VAL: 0.32004374265670776
INFO:root:38
Train: 0.3005099296569824 VAL: 0.3096526861190796
INFO:root:39
Train: 0.2987365424633026 VAL: 0.2950901389122009
INFO:root:40
Train: 0.3039841055870056 VAL: 0.3064621686935425
INFO:root:41
Train: 0.2972797751426697 VAL: 0.3374843895435333
INFO:root:42
Train: 0.3030646741390228 VAL: 0.3062153458595276
INFO:root:43
Train: 0.2994912564754486 VAL: 0.30299198627471924
INFO:root:44
Train: 0.30071884393692017 VAL: 0.3036094605922699
INFO:root:45
Train: 0.2594197392463684 VAL: 0.31058478355407715
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 12.607449531555176 VAL: 0.5278140306472778
INFO:root:2
Train: 0.9378641247749329 VAL: 0.5652587413787842
INFO:root:3
Train: 0.6540150046348572 VAL: 0.4428359270095825
INFO:root:4
Train: 0.6253740787506104 VAL: 0.4323824942111969
INFO:root:5
Train: 0.5676547884941101 VAL: 0.3337915539741516
INFO:root:6
Train: 0.49072667956352234 VAL: 0.33766788244247437
INFO:root:7
Train: 0.4371604919433594 VAL: 0.32388418912887573
INFO:root:8
Train: 0.4547009766101837 VAL: 0.3175469636917114
INFO:root:9
Train: 0.438172310590744 VAL: 0.2620650827884674
INFO:root:10
Train: 0.37517049908638 VAL: 0.2497604787349701
INFO:root:11
Train: 0.4228394329547882 VAL: 0.24306368827819824
INFO:root:12
Train: 0.41082513332366943 VAL: 0.2452939748764038
INFO:root:13
Train: 0.3193525969982147 VAL: 0.24946939945220947
INFO:root:14
Train: 0.35858094692230225 VAL: 0.32898443937301636
INFO:root:15
Train: 0.342737078666687 VAL: 0.2485271394252777
INFO:root:16
Train: 0.32855793833732605 VAL: 0.25396472215652466
INFO:root:17
Train: 0.3136187493801117 VAL: 0.3991563618183136
INFO:root:18
Train: 0.32988259196281433 VAL: 0.257650226354599
INFO:root:19
Train: 0.3648897707462311 VAL: 0.24914038181304932
INFO:root:20
Train: 0.3157667815685272 VAL: 0.32664763927459717
INFO:root:21
Train: 0.3324103057384491 VAL: 0.3108799159526825
INFO:root:22
Train: 0.316510945558548 VAL: 0.24623531103134155
INFO:root:23
Train: 0.3173387348651886 VAL: 0.2550392746925354
INFO:root:24
Train: 0.30180373787879944 VAL: 0.28475701808929443
INFO:root:25
Train: 0.30017510056495667 VAL: 0.3058772683143616
INFO:root:26
Train: 0.3086283206939697 VAL: 0.2996075749397278
INFO:root:27
Train: 0.30625826120376587 VAL: 0.2790864408016205
INFO:root:28
Train: 0.27906009554862976 VAL: 0.2770219147205353
INFO:root:29
Train: 0.297931432723999 VAL: 0.28079330921173096
INFO:root:30
Train: 0.28892266750335693 VAL: 0.29856595396995544
INFO:root:31
Train: 0.3077112138271332 VAL: 0.29212135076522827
INFO:root:32
Train: 0.3087907135486603 VAL: 0.2904282212257385
INFO:root:33
Train: 0.30064669251441956 VAL: 0.3086777329444885
INFO:root:34
Train: 0.30793023109436035 VAL: 0.28899267315864563
INFO:root:35
Train: 0.29908567667007446 VAL: 0.2865062952041626
INFO:root:36
Train: 0.2969229519367218 VAL: 0.2955029010772705
INFO:root:37
Train: 0.29149875044822693 VAL: 0.2868727743625641
INFO:root:38
Train: 0.2950465977191925 VAL: 0.2936971187591553
INFO:root:39
Train: 0.29088953137397766 VAL: 0.28470438718795776
INFO:root:40
Train: 0.29914793372154236 VAL: 0.29129719734191895
INFO:root:41
Train: 0.29560524225234985 VAL: 0.28824377059936523
INFO:root:BEST VAL: 0.28824377059936523 TEST : 0.34959688782691956
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 13.543780326843262 VAL: 0.9411347508430481
INFO:root:2
Train: 1.0096454620361328 VAL: 0.6612098813056946
INFO:root:3
Train: 0.8625628352165222 VAL: 0.5355027914047241
INFO:root:4
Train: 0.625385582447052 VAL: 0.42777806520462036
INFO:root:5
Train: 0.5245797038078308 VAL: 0.35736432671546936
INFO:root:6
Train: 0.4424128830432892 VAL: 0.2854829430580139
INFO:root:7
Train: 0.4032563865184784 VAL: 0.2715470492839813
INFO:root:8
Train: 0.41175076365470886 VAL: 0.35183313488960266
INFO:root:9
Train: 0.4030049741268158 VAL: 0.27764177322387695
INFO:root:10
Train: 0.4390305280685425 VAL: 0.27043405175209045
INFO:root:11
Train: 0.38047340512275696 VAL: 0.2518397569656372
INFO:root:12
Train: 0.3344291150569916 VAL: 0.30316096544265747
INFO:root:13
Train: 0.3317624628543854 VAL: 0.2583892345428467
INFO:root:14
Train: 0.3174320459365845 VAL: 0.24689874053001404
INFO:root:15
Train: 0.30881044268608093 VAL: 0.26312702894210815
INFO:root:16
Train: 0.3143261969089508 VAL: 0.2807309925556183
INFO:root:17
Train: 0.31791460514068604 VAL: 0.2799958884716034
INFO:root:18
Train: 0.3159430921077728 VAL: 0.28387251496315
INFO:root:19
Train: 0.30551213026046753 VAL: 0.2828575074672699
INFO:root:20
Train: 0.3059532642364502 VAL: 0.27886348962783813
INFO:root:21
Train: 0.31272709369659424 VAL: 0.27258384227752686
INFO:root:22
Train: 0.30248942971229553 VAL: 0.27369821071624756
INFO:root:23
Train: 0.28760308027267456 VAL: 0.2778564691543579
INFO:root:24
Train: 0.30116140842437744 VAL: 0.29343920946121216
INFO:root:25
Train: 0.29886648058891296 VAL: 0.27964839339256287
INFO:root:26
Train: 0.292772501707077 VAL: 0.2797417640686035
INFO:root:27
Train: 0.29140642285346985 VAL: 0.2820051312446594
INFO:root:28
Train: 0.2990264892578125 VAL: 0.28073349595069885
INFO:root:29
Train: 0.2930852770805359 VAL: 0.27854853868484497
INFO:root:30
Train: 0.299598753452301 VAL: 0.2823243737220764
INFO:root:31
Train: 0.2798348665237427 VAL: 0.267489492893219
INFO:root:32
Train: 0.2950657308101654 VAL: 0.27233779430389404
INFO:root:33
Train: 0.2976438105106354 VAL: 0.2894880175590515
INFO:root:34
Train: 0.27633896470069885 VAL: 0.2795407474040985
INFO:root:35
Train: 0.2947216331958771 VAL: 0.26864469051361084
INFO:root:36
Train: 0.29149264097213745 VAL: 0.2922128140926361
INFO:root:37
Train: 0.3003333508968353 VAL: 0.2752913236618042
INFO:root:38
Train: 0.2705381214618683 VAL: 0.2857455015182495
INFO:root:39
Train: 0.2976212203502655 VAL: 0.27647316455841064
INFO:root:40
Train: 0.27581748366355896 VAL: 0.27622365951538086
INFO:root:41
Train: 0.2917596399784088 VAL: 0.28058522939682007
INFO:root:42
Train: 0.2919890880584717 VAL: 0.27695176005363464
INFO:root:43
Train: 0.28654351830482483 VAL: 0.2790542244911194
INFO:root:44
Train: 0.27982911467552185 VAL: 0.27354896068573
INFO:root:BEST VAL: 0.27354896068573 TEST : 0.35496190190315247
