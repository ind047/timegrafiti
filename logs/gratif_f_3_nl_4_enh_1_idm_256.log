INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=3, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 22.85758399963379 VAL: 1.267869234085083
INFO:root:2
Train: 0.7862802147865295 VAL: 0.6793801188468933
INFO:root:3
Train: 0.6123932003974915 VAL: 0.5202248096466064
INFO:root:4
Train: 0.48827624320983887 VAL: 0.550271213054657
INFO:root:5
Train: 0.4787961542606354 VAL: 0.5409257411956787
INFO:root:6
Train: 0.418255478143692 VAL: 0.36023226380348206
INFO:root:7
Train: 0.6051644682884216 VAL: 0.36711233854293823
INFO:root:8
Train: 0.42372098565101624 VAL: 0.35227879881858826
INFO:root:9
Train: 0.39435410499572754 VAL: 0.33099785447120667
INFO:root:10
Train: 0.3966255187988281 VAL: 0.30538299679756165
INFO:root:11
Train: 0.374152272939682 VAL: 0.38549453020095825
INFO:root:12
Train: 0.3883436620235443 VAL: 0.29183533787727356
INFO:root:13
Train: 0.33247876167297363 VAL: 0.32027944922447205
INFO:root:14
Train: 0.3799159526824951 VAL: 0.3125999867916107
INFO:root:15
Train: 0.3825105130672455 VAL: 0.32397595047950745
INFO:root:16
Train: 0.37773218750953674 VAL: 0.2962711453437805
INFO:root:17
Train: 0.335483580827713 VAL: 0.3283388614654541
INFO:root:18
Train: 0.34088313579559326 VAL: 0.27861788868904114
INFO:root:19
Train: 0.33703696727752686 VAL: 0.28974395990371704
INFO:root:20
Train: 0.3604729473590851 VAL: 0.27127882838249207
INFO:root:21
Train: 0.389758437871933 VAL: 0.321367472410202
INFO:root:22
Train: 0.3653824031352997 VAL: 0.32660216093063354
INFO:root:23
Train: 0.3333820104598999 VAL: 0.3465759754180908
INFO:root:24
Train: 0.35253751277923584 VAL: 0.302310585975647
INFO:root:25
Train: 0.34411993622779846 VAL: 0.2906893491744995
INFO:root:26
Train: 0.2946401536464691 VAL: 0.26928508281707764
INFO:root:27
Train: 0.32141953706741333 VAL: 0.2760276198387146
INFO:root:28
Train: 0.32539549469947815 VAL: 0.2613980174064636
INFO:root:29
Train: 0.31500330567359924 VAL: 0.26214417815208435
INFO:root:30
Train: 0.3087705671787262 VAL: 0.26747018098831177
INFO:root:31
Train: 0.31280532479286194 VAL: 0.2777540385723114
INFO:root:32
Train: 0.30730047821998596 VAL: 0.27887827157974243
INFO:root:33
Train: 0.317126601934433 VAL: 0.28446704149246216
INFO:root:34
Train: 0.33807942271232605 VAL: 0.2646193504333496
INFO:root:35
Train: 0.31383004784584045 VAL: 0.29902708530426025
INFO:root:36
Train: 0.3977859914302826 VAL: 0.27886703610420227
INFO:root:37
Train: 0.36179447174072266 VAL: 0.32530874013900757
INFO:root:38
Train: 0.3743293285369873 VAL: 0.363639235496521
INFO:root:39
Train: 0.4266071617603302 VAL: 0.368554949760437
INFO:root:40
Train: 0.40132448077201843 VAL: 0.3372909724712372
INFO:root:41
Train: 0.37513837218284607 VAL: 0.3009057641029358
INFO:root:42
Train: 0.3217587172985077 VAL: 0.2890348434448242
INFO:root:43
Train: 0.33085283637046814 VAL: 0.2746528089046478
INFO:root:44
Train: 0.31517741084098816 VAL: 0.27365201711654663
INFO:root:45
Train: 0.3286171853542328 VAL: 0.3025646507740021
INFO:root:46
Train: 0.3421907126903534 VAL: 0.29483741521835327
INFO:root:47
Train: 0.3381606638431549 VAL: 0.27922624349594116
INFO:root:48
Train: 0.3554037809371948 VAL: 0.26466891169548035
INFO:root:49
Train: 0.3330465853214264 VAL: 0.30325812101364136
INFO:root:50
Train: 0.33989202976226807 VAL: 0.2967219650745392
INFO:root:51
Train: 0.34444859623908997 VAL: 0.2887306213378906
INFO:root:52
Train: 0.3348584473133087 VAL: 0.2827707827091217
INFO:root:53
Train: 0.30295422673225403 VAL: 0.2824462354183197
INFO:root:54
Train: 0.31320080161094666 VAL: 0.27816957235336304
INFO:root:55
Train: 0.28215062618255615 VAL: 0.2876499891281128
INFO:root:56
Train: 0.3373672664165497 VAL: 0.3660968244075775
INFO:root:57
Train: 0.5768674612045288 VAL: 0.5982438325881958
INFO:root:58
Train: 0.5519880056381226 VAL: 0.33626818656921387
INFO:root:BEST VAL: 0.33626818656921387 TEST : 0.2693195939064026
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=3, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='mimiciv')
INFO:root:{'input_dim': 100, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.7573879957199097 VAL: 0.29534417390823364
INFO:root:2
Train: 0.2895287871360779 VAL: 0.27919963002204895
INFO:root:3
Train: 0.2758329212665558 VAL: 0.2667575180530548
INFO:root:4
Train: 0.262708842754364 VAL: 0.2652488350868225
INFO:root:5
Train: 0.2572802007198334 VAL: 0.2606881558895111
INFO:root:6
Train: 0.2546963691711426 VAL: 0.27088314294815063
INFO:root:7
Train: 0.2512786090373993 VAL: 0.25047048926353455
INFO:root:8
Train: 0.2446165531873703 VAL: 0.2537093162536621
INFO:root:9
Train: 0.24254527688026428 VAL: 0.24388466775417328
INFO:root:10
Train: 0.24257823824882507 VAL: 0.24276447296142578
INFO:root:11
Train: 0.23966580629348755 VAL: 0.24379479885101318
INFO:root:12
Train: 0.23536677658557892 VAL: 0.24371552467346191
INFO:root:13
Train: 0.23210026323795319 VAL: 0.24615874886512756
INFO:root:14
Train: 0.23718613386154175 VAL: 0.2461397349834442
INFO:root:15
Train: 0.23209711909294128 VAL: 0.24216507375240326
INFO:root:16
Train: 0.22992579638957977 VAL: 0.2353336662054062
INFO:root:17
Train: 268563169280.0 VAL: 1963776384.0
INFO:root:18
Train: 2678390016.0 VAL: 21510869745664.0
INFO:root:19
Train: 18599225851904.0 VAL: 435240896.0
INFO:root:20
Train: 4506896384.0 VAL: 8395120128.0
INFO:root:21
Train: 995130240.0 VAL: 286779584.0
INFO:root:22
Train: 552608576.0 VAL: 77719008.0
INFO:root:23
Train: 1817554059264.0 VAL: 45091676160.0
INFO:root:24
Train: 3886755584.0 VAL: 1079820032.0
INFO:root:25
Train: 2149320097792.0 VAL: 3754827776.0
INFO:root:26
Train: 58727398899712.0 VAL: 1475145105408.0
INFO:root:27
Train: 141558251520.0 VAL: 18611482624.0
INFO:root:28
Train: 14003394560.0 VAL: 10300377088.0
INFO:root:29
Train: 9686010880.0 VAL: 7491214336.0
INFO:root:30
Train: 7707409920.0 VAL: 5830696960.0
INFO:root:31
Train: 166047009210368.0 VAL: 206705229824.0
INFO:root:32
Train: 218029506560.0 VAL: 180708376576.0
INFO:root:33
Train: 136885674442752.0 VAL: 8292253302784.0
INFO:root:34
Train: 1141942012346368.0 VAL: 752795320320.0
INFO:root:35
Train: 6739973373952.0 VAL: 8940678021120.0
INFO:root:36
Train: 45823815581696.0 VAL: 7507926319104.0
INFO:root:37
Train: 5145154813952.0 VAL: 1581426540544.0
INFO:root:38
Train: 2272155402240.0 VAL: 1092400054272.0
INFO:root:39
Train: 901691211776.0 VAL: 847165390848.0
INFO:root:40
Train: 690773753856.0 VAL: 562258247680.0
INFO:root:41
Train: 489652092928.0 VAL: 218905346048.0
INFO:root:42
Train: 255532531712.0 VAL: 227440771072.0
INFO:root:43
Train: 249864650752.0 VAL: 253808721920.0
INFO:root:44
Train: 288307183616.0 VAL: 284424536064.0
INFO:root:45
Train: 334424670208.0 VAL: 1271778770944.0
INFO:root:46
Train: 444084912128.0 VAL: 309426323456.0
INFO:root:BEST VAL: 309426323456.0 TEST : 0.2357248067855835
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=3, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=256, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 1, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 1.899889349937439 VAL: 0.32665950059890747
INFO:root:2
Train: 0.318177729845047 VAL: 0.29787760972976685
INFO:root:3
Train: 0.30317357182502747 VAL: 0.30733251571655273
INFO:root:4
Train: 0.30404898524284363 VAL: 0.2963752746582031
INFO:root:5
Train: 0.301699697971344 VAL: 0.29907628893852234
INFO:root:6
Train: 0.299356073141098 VAL: 0.29571348428726196
INFO:root:7
Train: 0.2978844940662384 VAL: 0.29518258571624756
INFO:root:8
Train: 0.2996845543384552 VAL: 0.2948300838470459
INFO:root:9
Train: 0.2976762056350708 VAL: 0.29399076104164124
INFO:root:10
Train: 0.29631417989730835 VAL: 0.2959180176258087
INFO:root:11
Train: 0.2949204742908478 VAL: 0.29167184233665466
INFO:root:12
Train: 0.2960602641105652 VAL: 0.2957068681716919
INFO:root:13
Train: 0.2950994074344635 VAL: 0.30233508348464966
INFO:root:14
Train: 0.29603061079978943 VAL: 0.2978249788284302
INFO:root:15
Train: 0.2952253520488739 VAL: 0.29559126496315
INFO:root:16
Train: 0.2924509346485138 VAL: 0.29879143834114075
INFO:root:17
Train: 0.29324060678482056 VAL: 0.2956388592720032
INFO:root:18
Train: 0.2917213439941406 VAL: 0.29106244444847107
INFO:root:19
Train: 0.2913553714752197 VAL: 0.2960819602012634
INFO:root:20
Train: 0.2897355258464813 VAL: 0.3001015782356262
INFO:root:21
Train: 0.29104894399642944 VAL: 0.29317784309387207
INFO:root:22
Train: 0.2882153391838074 VAL: 0.29021185636520386
INFO:root:23
Train: 0.2886354327201843 VAL: 0.295232355594635
INFO:root:24
Train: 0.28903114795684814 VAL: 0.2911323308944702
INFO:root:25
Train: 0.2885923683643341 VAL: 0.2925821542739868
INFO:root:26
Train: 0.28860175609588623 VAL: 0.29386937618255615
INFO:root:27
Train: 0.2884017527103424 VAL: 0.2915215492248535
INFO:root:28
Train: 0.2875811755657196 VAL: 0.2875983715057373
INFO:root:29
Train: 0.2864045202732086 VAL: 0.28786641359329224
INFO:root:30
Train: 0.28541940450668335 VAL: 0.2985573709011078
INFO:root:31
Train: 0.28692126274108887 VAL: 0.28710973262786865
INFO:root:32
Train: 0.28479889035224915 VAL: 0.3047850430011749
INFO:root:33
Train: 0.2856825888156891 VAL: 0.29495853185653687
INFO:root:34
Train: 0.2850891351699829 VAL: 0.290732204914093
INFO:root:35
Train: 0.28362229466438293 VAL: 0.29505667090415955
INFO:root:36
Train: 0.28353193402290344 VAL: 0.2887193560600281
INFO:root:37
Train: 0.28336161375045776 VAL: 0.2986517548561096
INFO:root:38
Train: 0.2792157530784607 VAL: 0.2896585464477539
INFO:root:39
Train: 0.28061696887016296 VAL: 0.2904888987541199
INFO:root:40
Train: 0.2818877100944519 VAL: 0.2909170091152191
INFO:root:41
Train: 0.2782825529575348 VAL: 0.2917534112930298
INFO:root:42
Train: 0.2780258357524872 VAL: 0.29039886593818665
INFO:root:43
Train: 0.272148072719574 VAL: 0.28961238265037537
INFO:root:44
Train: 0.26913172006607056 VAL: 0.2906135022640228
INFO:root:45
Train: 0.26752638816833496 VAL: 0.28827857971191406
INFO:root:46
Train: 0.26517996191978455 VAL: 0.289933979511261
INFO:root:47
Train: 0.2654130160808563 VAL: 0.28793710470199585
INFO:root:48
Train: 0.2662431001663208 VAL: 0.2914498448371887
INFO:root:49
Train: 0.26298636198043823 VAL: 0.2909032106399536
INFO:root:50
Train: 0.26175495982170105 VAL: 0.2950102686882019
INFO:root:51
Train: 0.2606925368309021 VAL: 0.29317861795425415
INFO:root:52
Train: 0.2654707729816437 VAL: 0.29222267866134644
INFO:root:53
Train: 0.26017171144485474 VAL: 0.29385849833488464
INFO:root:54
Train: 0.25091445446014404 VAL: 0.2914600968360901
INFO:root:55
Train: 0.2480066865682602 VAL: 0.3001815974712372
INFO:root:56
Train: 0.24462172389030457 VAL: 0.29630765318870544
INFO:root:57
Train: 0.24193352460861206 VAL: 0.2990413308143616
INFO:root:58
Train: 0.23955391347408295 VAL: 0.30233484506607056
INFO:root:59
Train: 0.23767997324466705 VAL: 0.30405449867248535
INFO:root:60
Train: 0.23698163032531738 VAL: 0.3013118803501129
INFO:root:61
Train: 0.2379731386899948 VAL: 0.2986137866973877
INFO:root:BEST VAL: 0.2986137866973877 TEST : 0.28847140073776245
