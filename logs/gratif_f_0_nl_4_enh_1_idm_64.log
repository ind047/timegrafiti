INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=64, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 1, 'latent_dim': 64, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.9659541249275208 VAL: 0.7620831727981567
INFO:root:2
Train: 0.6062878966331482 VAL: 0.622620701789856
INFO:root:3
Train: 0.5507693290710449 VAL: 0.48080646991729736
INFO:root:4
Train: 0.4215586483478546 VAL: 0.3369351029396057
INFO:root:5
Train: 0.3386804163455963 VAL: 0.31920695304870605
INFO:root:6
Train: 0.33424112200737 VAL: 0.4057142436504364
INFO:root:7
Train: 0.32511964440345764 VAL: 0.8348077535629272
INFO:root:8
Train: 0.33386746048927307 VAL: 0.38918834924697876
INFO:root:9
Train: 0.33094415068626404 VAL: 0.462281197309494
INFO:root:10
Train: 0.330657958984375 VAL: 0.5158369541168213
INFO:root:11
Train: 0.31817135214805603 VAL: 0.46091049909591675
INFO:root:12
Train: 0.32748568058013916 VAL: 0.45129477977752686
INFO:root:13
Train: 0.31895554065704346 VAL: 0.362271249294281
INFO:root:14
Train: 0.3143129050731659 VAL: 0.4490516185760498
INFO:root:15
Train: 0.3080681264400482 VAL: 0.4428444802761078
INFO:root:16
Train: 0.30189868807792664 VAL: 0.3994554281234741
INFO:root:17
Train: 0.3069378137588501 VAL: 0.41431060433387756
INFO:root:18
Train: 0.3002864420413971 VAL: 0.46588069200515747
INFO:root:19
Train: 0.3047398626804352 VAL: 0.4601961672306061
INFO:root:20
Train: 0.30574920773506165 VAL: 0.4298194944858551
INFO:root:21
Train: 0.2964421510696411 VAL: 0.4030480980873108
INFO:root:22
Train: 0.2981056869029999 VAL: 0.39485132694244385
INFO:root:23
Train: 0.26844263076782227 VAL: 0.44199126958847046
INFO:root:24
Train: 0.305480033159256 VAL: 0.4223722517490387
INFO:root:25
Train: 0.30180561542510986 VAL: 0.4215155839920044
INFO:root:26
Train: 0.28159669041633606 VAL: 0.4887545108795166
INFO:root:27
Train: 0.30427369475364685 VAL: 0.3729090094566345
INFO:root:28
Train: 0.304979532957077 VAL: 0.3830944299697876
INFO:root:29
Train: 0.2978643476963043 VAL: 0.4060749411582947
INFO:root:30
Train: 0.30087098479270935 VAL: 0.41780519485473633
INFO:root:31
Train: 0.30008751153945923 VAL: 0.43176302313804626
INFO:root:32
Train: 0.30042165517807007 VAL: 0.40213698148727417
INFO:root:33
Train: 0.3000262677669525 VAL: 0.3948451280593872
INFO:root:34
Train: 0.29389718174934387 VAL: 0.44358029961586
INFO:root:35
Train: 0.3049663007259369 VAL: 0.40043801069259644
INFO:root:BEST VAL: 0.40043801069259644 TEST : 0.19685325026512146
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=1, latent_dim=64, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 1, 'latent_dim': 64, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.45411816239356995 VAL: 0.3604438304901123
INFO:root:2
Train: 0.32000648975372314 VAL: 0.30597537755966187
INFO:root:3
Train: 0.30412986874580383 VAL: 0.301999568939209
INFO:root:4
Train: 0.3000636696815491 VAL: 0.30666249990463257
INFO:root:5
Train: 0.29721564054489136 VAL: 0.294130802154541
INFO:root:6
Train: 0.29751622676849365 VAL: 0.29208290576934814
INFO:root:7
Train: 0.29742538928985596 VAL: 0.29489535093307495
INFO:root:8
Train: 0.2956981360912323 VAL: 0.29168379306793213
INFO:root:9
Train: 0.2918345034122467 VAL: 0.29207152128219604
INFO:root:10
Train: 0.29212936758995056 VAL: 0.29618141055107117
INFO:root:11
Train: 0.2914142608642578 VAL: 0.2949117422103882
INFO:root:12
Train: 0.2900014817714691 VAL: 0.2921357750892639
INFO:root:13
Train: 0.2906510829925537 VAL: 0.29289618134498596
INFO:root:14
Train: 0.2896243631839752 VAL: 0.29084324836730957
INFO:root:15
Train: 0.2887272238731384 VAL: 0.2894793748855591
INFO:root:16
Train: 0.2890489995479584 VAL: 0.2935553193092346
INFO:root:17
Train: 0.28783783316612244 VAL: 0.2892017364501953
INFO:root:18
Train: 0.2880314886569977 VAL: 0.2911473512649536
INFO:root:19
Train: 0.28586938977241516 VAL: 0.2906847596168518
INFO:root:20
Train: 0.2867318093776703 VAL: 0.2910712957382202
INFO:root:21
Train: 0.28657272458076477 VAL: 0.28874272108078003
INFO:root:22
Train: 0.2851067781448364 VAL: 0.28997179865837097
INFO:root:23
Train: 0.2836773991584778 VAL: 0.294096976518631
INFO:root:24
Train: 0.283214271068573 VAL: 0.2906948924064636
INFO:root:25
Train: 0.28370535373687744 VAL: 0.2902372479438782
INFO:root:26
Train: 0.28045564889907837 VAL: 0.2919238209724426
INFO:root:27
Train: 0.28512609004974365 VAL: 0.2911352813243866
INFO:root:28
Train: 0.28373947739601135 VAL: 0.29197418689727783
INFO:root:29
Train: 0.2833200991153717 VAL: 0.2887532711029053
INFO:root:30
Train: 0.28100234270095825 VAL: 0.2912105321884155
INFO:root:31
Train: 0.2805367112159729 VAL: 0.28922271728515625
INFO:root:32
Train: 0.281474232673645 VAL: 0.2916927933692932
INFO:root:33
Train: 0.2766943871974945 VAL: 0.2891385853290558
INFO:root:34
Train: 0.2747381627559662 VAL: 0.2886699438095093
INFO:root:35
Train: 0.2750946581363678 VAL: 0.288510799407959
INFO:root:36
Train: 0.2725815176963806 VAL: 0.29644426703453064
INFO:root:37
Train: 0.27468520402908325 VAL: 0.2901575565338135
INFO:root:38
Train: 0.2711400091648102 VAL: 0.2915084958076477
INFO:root:39
Train: 0.27210524678230286 VAL: 0.29102030396461487
INFO:root:40
Train: 0.2731548249721527 VAL: 0.29359132051467896
INFO:root:41
Train: 0.2699289619922638 VAL: 0.28989148139953613
INFO:root:42
Train: 0.26922672986984253 VAL: 0.29236820340156555
INFO:root:43
Train: 0.26822203397750854 VAL: 0.2902922034263611
INFO:root:44
Train: 0.26883432269096375 VAL: 0.28907907009124756
INFO:root:45
Train: 0.2677748501300812 VAL: 0.295232892036438
INFO:root:46
Train: 0.26696082949638367 VAL: 0.2910735011100769
INFO:root:47
Train: 0.2624463737010956 VAL: 0.29379701614379883
INFO:root:48
Train: 0.2603200674057007 VAL: 0.29711848497390747
INFO:root:49
Train: 0.25963762402534485 VAL: 0.2954804599285126
INFO:root:50
Train: 0.25807082653045654 VAL: 0.29861533641815186
INFO:root:51
Train: 0.2572331726551056 VAL: 0.29410481452941895
INFO:root:52
Train: 0.2551895081996918 VAL: 0.29591143131256104
INFO:root:53
Train: 0.2544432282447815 VAL: 0.2973085343837738
INFO:root:54
Train: 0.25446873903274536 VAL: 0.29563552141189575
INFO:root:55
Train: 0.2548410892486572 VAL: 0.2995093762874603
INFO:root:56
Train: 0.25365227460861206 VAL: 0.29562294483184814
INFO:root:57
Train: 0.25016939640045166 VAL: 0.30326777696609497
INFO:root:58
Train: 0.24748685956001282 VAL: 0.29944366216659546
INFO:root:59
Train: 0.2453538179397583 VAL: 0.29835888743400574
INFO:root:60
Train: 0.2452775090932846 VAL: 0.3005094528198242
INFO:root:61
Train: 0.24438470602035522 VAL: 0.30237439274787903
INFO:root:62
Train: 0.24336202442646027 VAL: 0.3011617660522461
INFO:root:63
Train: 0.24265417456626892 VAL: 0.30285942554473877
INFO:root:64
Train: 0.242027148604393 VAL: 0.30286312103271484
INFO:root:65
Train: 0.240858256816864 VAL: 0.30276620388031006
INFO:root:BEST VAL: 0.30276620388031006 TEST : 0.288484662771225
