INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 20.807615280151367 VAL: 1.0815494060516357
INFO:root:2
Train: 0.7537431120872498 VAL: 0.544756293296814
INFO:root:3
Train: 0.5228835940361023 VAL: 0.5064562559127808
INFO:root:4
Train: 0.5071235299110413 VAL: 0.34822243452072144
INFO:root:5
Train: 0.4738211929798126 VAL: 0.33784380555152893
INFO:root:6
Train: 0.5174688696861267 VAL: 0.5763250589370728
INFO:root:7
Train: 1.1558775901794434 VAL: 0.4043973982334137
INFO:root:8
Train: 0.5569154024124146 VAL: 0.4903900921344757
INFO:root:9
Train: 0.41393423080444336 VAL: 0.26641732454299927
INFO:root:10
Train: 0.4356934726238251 VAL: 0.30728381872177124
INFO:root:11
Train: 0.43139171600341797 VAL: 0.2915137708187103
INFO:root:12
Train: 0.34736037254333496 VAL: 0.3379663825035095
INFO:root:13
Train: 0.3112460672855377 VAL: 0.2990821599960327
INFO:root:14
Train: 0.3038879632949829 VAL: 0.28665193915367126
INFO:root:15
Train: 0.3066309988498688 VAL: 0.2787649631500244
INFO:root:16
Train: 0.30664941668510437 VAL: 0.28448301553726196
INFO:root:17
Train: 0.3111100196838379 VAL: 0.2709069848060608
INFO:root:18
Train: 0.3089442253112793 VAL: 0.2993151545524597
INFO:root:19
Train: 0.30405083298683167 VAL: 0.2684277594089508
INFO:root:20
Train: 0.29852065443992615 VAL: 0.27624696493148804
INFO:root:21
Train: 0.26641711592674255 VAL: 0.3044203817844391
INFO:root:22
Train: 0.29670774936676025 VAL: 0.29354146122932434
INFO:root:23
Train: 0.30173274874687195 VAL: 0.2605472803115845
INFO:root:24
Train: 0.3032290041446686 VAL: 0.28455743193626404
INFO:root:25
Train: 0.3034364879131317 VAL: 0.2997311055660248
INFO:root:26
Train: 0.300127774477005 VAL: 0.27933067083358765
INFO:root:27
Train: 0.29805096983909607 VAL: 0.2856772840023041
INFO:root:28
Train: 0.2930329442024231 VAL: 0.2829669415950775
INFO:root:29
Train: 0.29514560103416443 VAL: 0.28499293327331543
INFO:root:30
Train: 0.29521071910858154 VAL: 0.2808435559272766
INFO:root:31
Train: 0.2872069478034973 VAL: 0.27878352999687195
INFO:root:32
Train: 0.28827953338623047 VAL: 0.30539777874946594
INFO:root:33
Train: 0.29117465019226074 VAL: 0.2910535931587219
INFO:root:34
Train: 0.2948584258556366 VAL: 0.26398366689682007
INFO:root:35
Train: 0.29426881670951843 VAL: 0.27314573526382446
INFO:root:36
Train: 0.29767873883247375 VAL: 0.28951600193977356
INFO:root:37
Train: 0.2955760359764099 VAL: 0.2824072539806366
INFO:root:38
Train: 0.27595141530036926 VAL: 0.28363239765167236
INFO:root:39
Train: 0.2951080799102783 VAL: 0.2767142951488495
INFO:root:40
Train: 0.2854149341583252 VAL: 0.27745872735977173
INFO:root:41
Train: 0.2913999855518341 VAL: 0.2796213626861572
INFO:root:42
Train: 0.2977637052536011 VAL: 0.29688695073127747
INFO:root:43
Train: 0.293911337852478 VAL: 0.27414992451667786
INFO:root:44
Train: 0.2975974678993225 VAL: 0.28840404748916626
INFO:root:45
Train: 0.28952184319496155 VAL: 0.27696266770362854
INFO:root:46
Train: 0.27977901697158813 VAL: 0.28717026114463806
INFO:root:47
Train: 0.2748083174228668 VAL: 0.2802034616470337
INFO:root:48
Train: 0.28839483857154846 VAL: 0.27600547671318054
INFO:root:49
Train: 0.29242733120918274 VAL: 0.2826458215713501
INFO:root:50
Train: 0.28605541586875916 VAL: 0.27695995569229126
INFO:root:51
Train: 0.2922668159008026 VAL: 0.27948981523513794
INFO:root:52
Train: 0.29231002926826477 VAL: 0.27891242504119873
INFO:root:53
Train: 0.2928086817264557 VAL: 0.2780439853668213
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 12.416549682617188 VAL: 0.7531905174255371
INFO:root:2
Train: 0.7127769589424133 VAL: 0.6637758612632751
INFO:root:3
Train: 0.6401635408401489 VAL: 0.5326169729232788
INFO:root:4
Train: 0.558072566986084 VAL: 0.565786600112915
INFO:root:5
Train: 0.425508588552475 VAL: 0.3370121419429779
INFO:root:6
Train: 0.33784523606300354 VAL: 0.28170058131217957
INFO:root:7
Train: 0.3599388301372528 VAL: 0.3797045350074768
INFO:root:8
Train: 0.35196805000305176 VAL: 0.26022112369537354
INFO:root:9
Train: 0.3871326446533203 VAL: 0.27126485109329224
INFO:root:10
Train: 0.34274768829345703 VAL: 0.3679771423339844
INFO:root:11
Train: 0.3882703483104706 VAL: 0.2752115726470947
INFO:root:12
Train: 0.41307368874549866 VAL: 0.2891075611114502
INFO:root:13
Train: 0.36676037311553955 VAL: 0.2487325817346573
INFO:root:14
Train: 0.33263617753982544 VAL: 0.2905023992061615
INFO:root:15
Train: 0.38758528232574463 VAL: 0.352400004863739
INFO:root:16
Train: 0.37555286288261414 VAL: 0.24950043857097626
INFO:root:17
Train: 0.3304816782474518 VAL: 0.3411303758621216
INFO:root:18
Train: 0.3308488726615906 VAL: 0.33823567628860474
INFO:root:19
Train: 0.29865238070487976 VAL: 0.2669396996498108
INFO:root:20
Train: 0.3117813169956207 VAL: 0.25930115580558777
INFO:root:21
Train: 0.30423250794410706 VAL: 0.28291359543800354
INFO:root:22
Train: 0.310260534286499 VAL: 0.26997897028923035
INFO:root:23
Train: 0.304826945066452 VAL: 0.2901023030281067
INFO:root:24
Train: 0.30345532298088074 VAL: 0.27859795093536377
INFO:root:25
Train: 0.29843059182167053 VAL: 0.27092382311820984
INFO:root:26
Train: 0.30365097522735596 VAL: 0.273548424243927
INFO:root:27
Train: 0.30610790848731995 VAL: 0.2682144045829773
INFO:root:28
Train: 0.2889266908168793 VAL: 0.2780531644821167
INFO:root:29
Train: 0.29151615500450134 VAL: 0.27583763003349304
INFO:root:30
Train: 0.2970599830150604 VAL: 0.2676197290420532
INFO:root:31
Train: 0.29644036293029785 VAL: 0.27420324087142944
INFO:root:32
Train: 0.2957339882850647 VAL: 0.276579350233078
INFO:root:33
Train: 0.3008326590061188 VAL: 0.26364773511886597
INFO:root:34
Train: 0.2983976900577545 VAL: 0.27192965149879456
INFO:root:35
Train: 0.29256168007850647 VAL: 0.26969751715660095
INFO:root:36
Train: 0.2965611219406128 VAL: 0.2703283727169037
INFO:root:37
Train: 0.292522132396698 VAL: 0.2653789520263672
INFO:root:38
Train: 0.29053089022636414 VAL: 0.2703973352909088
INFO:root:39
Train: 0.26989200711250305 VAL: 0.2663979232311249
INFO:root:40
Train: 0.27106159925460815 VAL: 0.26722294092178345
INFO:root:41
Train: 0.2799571454524994 VAL: 0.2656855285167694
INFO:root:42
Train: 0.2940356433391571 VAL: 0.26931869983673096
INFO:root:43
Train: 0.2941029369831085 VAL: 0.26585572957992554
INFO:root:BEST VAL: 0.26585572957992554 TEST : 0.3574955463409424
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 19.502527236938477 VAL: 0.8760182857513428
INFO:root:2
Train: 0.7330811023712158 VAL: 0.6193915605545044
INFO:root:3
Train: 0.8638918995857239 VAL: 0.404801607131958
INFO:root:4
Train: 0.7333919405937195 VAL: 0.531875491142273
INFO:root:5
Train: 0.4947378933429718 VAL: 0.4035276770591736
INFO:root:6
Train: 0.4546583592891693 VAL: 3.678121566772461
INFO:root:7
Train: 1.0739794969558716 VAL: 0.367717444896698
INFO:root:8
Train: 0.6571789383888245 VAL: 0.4427579641342163
INFO:root:9
Train: 0.5104946494102478 VAL: 0.3072351813316345
INFO:root:10
Train: 0.39475008845329285 VAL: 0.3413114547729492
INFO:root:11
Train: 0.4133271276950836 VAL: 0.30629897117614746
INFO:root:12
Train: 0.383446604013443 VAL: 0.2744404077529907
INFO:root:13
Train: 0.3913475275039673 VAL: 0.2567712962627411
INFO:root:14
Train: 0.36367034912109375 VAL: 0.24527214467525482
INFO:root:15
Train: 0.3388148248195648 VAL: 0.24798056483268738
INFO:root:16
Train: 0.3492946922779083 VAL: 0.2632504999637604
INFO:root:17
Train: 0.31305986642837524 VAL: 0.23589107394218445
INFO:root:18
Train: 0.33676281571388245 VAL: 0.23633278906345367
INFO:root:19
Train: 0.32340914011001587 VAL: 0.3159787654876709
INFO:root:20
Train: 0.32140621542930603 VAL: 0.27769768238067627
INFO:root:21
Train: 0.3328794836997986 VAL: 0.26882344484329224
INFO:root:22
Train: 0.3253697454929352 VAL: 0.25402402877807617
INFO:root:23
Train: 0.29992273449897766 VAL: 0.23886969685554504
INFO:root:24
Train: 0.33657750487327576 VAL: 0.2353801131248474
INFO:root:25
Train: 0.3069668114185333 VAL: 0.3216230869293213
INFO:root:26
Train: 0.3510572612285614 VAL: 0.2609666585922241
INFO:root:27
Train: 0.35860979557037354 VAL: 0.23834803700447083
INFO:root:28
Train: 0.324594646692276 VAL: 0.6553523540496826
INFO:root:29
Train: 0.3444157540798187 VAL: 0.2451537698507309
INFO:root:30
Train: 0.32614073157310486 VAL: 0.25309526920318604
INFO:root:31
Train: 0.3289136588573456 VAL: 0.2352789044380188
INFO:root:32
Train: 0.32151779532432556 VAL: 0.27150121331214905
INFO:root:33
Train: 0.31016814708709717 VAL: 0.2661503255367279
INFO:root:34
Train: 0.302738219499588 VAL: 0.24410071969032288
INFO:root:35
Train: 0.43207618594169617 VAL: 0.26773908734321594
INFO:root:36
Train: 0.38515031337738037 VAL: 0.23939386010169983
INFO:root:37
Train: 0.37553802132606506 VAL: 0.2676239609718323
INFO:root:38
Train: 0.41297006607055664 VAL: 0.2629131078720093
INFO:root:39
Train: 0.3411131203174591 VAL: 0.2466820478439331
INFO:root:40
Train: 0.3308410346508026 VAL: 0.2926003038883209
INFO:root:41
Train: 0.316975861787796 VAL: 0.3073606491088867
INFO:root:42
Train: 0.30992016196250916 VAL: 0.27845799922943115
INFO:root:43
Train: 0.301679402589798 VAL: 0.2817639112472534
INFO:root:44
Train: 0.2763373851776123 VAL: 0.30590584874153137
INFO:root:45
Train: 0.30357441306114197 VAL: 0.29278767108917236
INFO:root:46
Train: 0.29043370485305786 VAL: 0.28828105330467224
INFO:root:47
Train: 0.2865598499774933 VAL: 0.2957852780818939
INFO:root:48
Train: 0.29719823598861694 VAL: 0.29793643951416016
INFO:root:49
Train: 0.29684731364250183 VAL: 0.299564391374588
INFO:root:50
Train: 0.30005037784576416 VAL: 0.29593968391418457
INFO:root:51
Train: 0.29901716113090515 VAL: 0.28956007957458496
INFO:root:52
Train: 0.30139070749282837 VAL: 0.3038213849067688
INFO:root:53
Train: 0.27959194779396057 VAL: 0.2981683313846588
INFO:root:54
Train: 0.2931237518787384 VAL: 0.30609357357025146
INFO:root:55
Train: 0.29812878370285034 VAL: 0.29508519172668457
INFO:root:56
Train: 0.295866459608078 VAL: 0.2944575250148773
INFO:root:57
Train: 0.2835991680622101 VAL: 0.2947430908679962
INFO:root:58
Train: 0.26293110847473145 VAL: 0.2944006323814392
INFO:root:59
Train: 0.29407384991645813 VAL: 0.2976666986942291
INFO:root:60
Train: 0.29226240515708923 VAL: 0.2941564917564392
INFO:root:61
Train: 0.2840152382850647 VAL: 0.30060744285583496
INFO:root:BEST VAL: 0.30060744285583496 TEST : 0.34880438446998596
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 13.647765159606934 VAL: 0.7949817180633545
INFO:root:2
Train: 0.6877842545509338 VAL: 0.614284098148346
INFO:root:3
Train: 0.6479278802871704 VAL: 0.4193824529647827
INFO:root:4
Train: 0.5062808394432068 VAL: 0.4524206221103668
INFO:root:5
Train: 0.47439679503440857 VAL: 0.3678726553916931
INFO:root:6
Train: 0.42229437828063965 VAL: 1.394669532775879
INFO:root:7
Train: 0.5313624739646912 VAL: 0.3087546229362488
INFO:root:8
Train: 0.3973220884799957 VAL: 0.5595303773880005
INFO:root:9
Train: 0.48335763812065125 VAL: 0.29181015491485596
INFO:root:10
Train: 0.37977245450019836 VAL: 0.685502290725708
INFO:root:11
Train: 0.3770861327648163 VAL: 0.27788016200065613
INFO:root:12
Train: 0.3996995985507965 VAL: 0.2405591905117035
INFO:root:13
Train: 0.378536581993103 VAL: 0.3758390545845032
INFO:root:14
Train: 0.38008710741996765 VAL: 0.2601471543312073
INFO:root:15
Train: 0.3400237560272217 VAL: 0.3737562894821167
INFO:root:16
Train: 0.341567724943161 VAL: 0.24286037683486938
INFO:root:17
Train: 0.32596355676651 VAL: 0.2412005513906479
INFO:root:18
Train: 0.4183844327926636 VAL: 0.27477532625198364
INFO:root:19
Train: 0.37558650970458984 VAL: 0.23666763305664062
INFO:root:20
Train: 0.3450852930545807 VAL: 0.2422182261943817
INFO:root:21
Train: 0.32483601570129395 VAL: 0.9169797897338867
INFO:root:22
Train: 0.42845749855041504 VAL: 0.23742619156837463
INFO:root:23
Train: 0.44329795241355896 VAL: 0.7412895560264587
INFO:root:24
Train: 0.3817775249481201 VAL: 0.26767632365226746
INFO:root:25
Train: 0.3576284348964691 VAL: 0.24177014827728271
INFO:root:26
Train: 0.32968875765800476 VAL: 0.41920554637908936
INFO:root:27
Train: 0.33474358916282654 VAL: 0.2750430107116699
INFO:root:28
Train: 0.32577380537986755 VAL: 0.2450389564037323
INFO:root:29
Train: 0.34001851081848145 VAL: 0.252081036567688
INFO:root:30
Train: 0.2782580852508545 VAL: 0.3155834376811981
INFO:root:31
Train: 0.29597821831703186 VAL: 0.3212130069732666
INFO:root:32
Train: 0.28589102625846863 VAL: 0.2822229862213135
INFO:root:33
Train: 0.3039572238922119 VAL: 0.2861548662185669
INFO:root:34
Train: 0.2730892598628998 VAL: 0.3098655045032501
INFO:root:35
Train: 0.28685787320137024 VAL: 0.3197800815105438
INFO:root:36
Train: 0.2968214154243469 VAL: 0.3144495487213135
INFO:root:37
Train: 0.28931722044944763 VAL: 0.2975477874279022
INFO:root:38
Train: 0.28305861353874207 VAL: 0.2994422912597656
INFO:root:39
Train: 0.2951996326446533 VAL: 0.3063908815383911
INFO:root:40
Train: 0.30108556151390076 VAL: 0.3161427080631256
INFO:root:41
Train: 0.2975636422634125 VAL: 0.30911219120025635
INFO:root:42
Train: 0.2987564504146576 VAL: 0.30015864968299866
INFO:root:43
Train: 0.29766079783439636 VAL: 0.2988203763961792
INFO:root:44
Train: 0.2979108691215515 VAL: 0.3073769807815552
INFO:root:45
Train: 0.29565688967704773 VAL: 0.30075573921203613
INFO:root:46
Train: 0.29219314455986023 VAL: 0.3045511245727539
INFO:root:47
Train: 0.2806659936904907 VAL: 0.3124920129776001
INFO:root:48
Train: 0.2995374798774719 VAL: 0.2970770299434662
INFO:root:49
Train: 0.29911425709724426 VAL: 0.30057767033576965
INFO:root:BEST VAL: 0.30057767033576965 TEST : 0.3433017134666443
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 13.83280086517334 VAL: 0.5081164836883545
INFO:root:2
Train: 0.6432079672813416 VAL: 1.7365431785583496
INFO:root:3
Train: 0.7490835189819336 VAL: 0.5465331673622131
INFO:root:4
Train: 0.6230100393295288 VAL: 0.4555831253528595
INFO:root:5
Train: 0.4753681421279907 VAL: 0.26055699586868286
INFO:root:6
Train: 0.3781379163265228 VAL: 0.289276123046875
INFO:root:7
Train: 0.34816789627075195 VAL: 0.243997722864151
INFO:root:8
Train: 0.3297030031681061 VAL: 0.2695331275463104
INFO:root:9
Train: 0.3178006410598755 VAL: 0.2500861883163452
INFO:root:10
Train: 0.3887948989868164 VAL: 0.23227813839912415
INFO:root:11
Train: 0.3354085385799408 VAL: 0.2601754069328308
INFO:root:12
Train: 0.3413712978363037 VAL: 0.2954953610897064
INFO:root:13
Train: 0.36838480830192566 VAL: 0.2715228199958801
INFO:root:14
Train: 0.34463468194007874 VAL: 0.29979681968688965
INFO:root:15
Train: 0.33799421787261963 VAL: 0.31594645977020264
INFO:root:16
Train: 0.31270769238471985 VAL: 0.26358962059020996
INFO:root:17
Train: 0.3521215617656708 VAL: 0.2775832414627075
INFO:root:18
Train: 0.3463912010192871 VAL: 0.29449647665023804
INFO:root:19
Train: 0.330670565366745 VAL: 0.268531858921051
INFO:root:20
Train: 0.321687251329422 VAL: 0.28327053785324097
INFO:root:21
Train: 0.30421632528305054 VAL: 0.281945139169693
INFO:root:22
Train: 0.31046372652053833 VAL: 0.2944021224975586
INFO:root:23
Train: 0.30705371499061584 VAL: 0.2972909212112427
INFO:root:24
Train: 0.3055688440799713 VAL: 0.29653269052505493
INFO:root:25
Train: 0.30427637696266174 VAL: 0.294100284576416
INFO:root:26
Train: 0.3032402992248535 VAL: 0.2970430850982666
INFO:root:27
Train: 0.273409366607666 VAL: 0.2883554697036743
INFO:root:28
Train: 0.3020714819431305 VAL: 0.2836242616176605
INFO:root:29
Train: 0.28732991218566895 VAL: 0.2869536876678467
INFO:root:30
Train: 0.30061864852905273 VAL: 0.29228588938713074
INFO:root:31
Train: 0.29813119769096375 VAL: 0.28324094414711
INFO:root:32
Train: 0.2843702733516693 VAL: 0.2902572751045227
INFO:root:33
Train: 0.28457561135292053 VAL: 0.28940701484680176
INFO:root:34
Train: 0.2961468994617462 VAL: 0.28751707077026367
INFO:root:35
Train: 0.29611313343048096 VAL: 0.28428417444229126
INFO:root:36
Train: 0.29275885224342346 VAL: 0.2860061228275299
INFO:root:37
Train: 0.28103312849998474 VAL: 0.28656697273254395
INFO:root:38
Train: 0.27655482292175293 VAL: 0.28654271364212036
INFO:root:39
Train: 0.2934110164642334 VAL: 0.2867111563682556
INFO:root:40
Train: 0.28657010197639465 VAL: 0.2866869568824768
INFO:root:BEST VAL: 0.2866869568824768 TEST : 0.3609539270401001
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=256, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 256, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 14.884476661682129 VAL: 0.49569910764694214
INFO:root:2
Train: 0.8259167671203613 VAL: 0.45162495970726013
INFO:root:3
Train: 0.5743852257728577 VAL: 0.5130077600479126
INFO:root:4
Train: 0.44957077503204346 VAL: 0.3764209449291229
INFO:root:5
Train: 0.43496060371398926 VAL: 0.9458937644958496
INFO:root:6
Train: 0.525725781917572 VAL: 0.2814668118953705
INFO:root:7
Train: 0.3798372745513916 VAL: 1.0615277290344238
INFO:root:8
Train: 0.3718864619731903 VAL: 0.2521504759788513
INFO:root:9
Train: 0.3676423728466034 VAL: 0.36041757464408875
INFO:root:10
Train: 0.38454291224479675 VAL: 0.27326351404190063
INFO:root:11
Train: 0.5174144506454468 VAL: 0.36776697635650635
INFO:root:12
Train: 0.3766894042491913 VAL: 0.2358885109424591
INFO:root:13
Train: 0.3584017753601074 VAL: 0.23807433247566223
INFO:root:14
Train: 0.318604439496994 VAL: 0.23837779462337494
INFO:root:15
Train: 0.37082943320274353 VAL: 0.26770251989364624
INFO:root:16
Train: 0.409951776266098 VAL: 0.3495461940765381
INFO:root:17
Train: 0.3691617548465729 VAL: 0.3831652104854584
INFO:root:18
Train: 0.4049030542373657 VAL: 0.2462194263935089
INFO:root:19
Train: 0.37268534302711487 VAL: 0.22951960563659668
INFO:root:20
Train: 0.3407544195652008 VAL: 0.8343770503997803
INFO:root:21
Train: 0.40928351879119873 VAL: 0.27457547187805176
INFO:root:22
Train: 0.35673511028289795 VAL: 0.2497248351573944
INFO:root:23
Train: 0.3576747179031372 VAL: 0.5619816780090332
INFO:root:24
Train: 0.4073469638824463 VAL: 0.2805591821670532
INFO:root:25
Train: 0.5355010628700256 VAL: 0.3039438724517822
INFO:root:26
Train: 0.43793627619743347 VAL: 0.29101115465164185
INFO:root:27
Train: 0.3776768445968628 VAL: 0.31553977727890015
INFO:root:28
Train: 0.3431133031845093 VAL: 0.8082237243652344
INFO:root:29
Train: 0.41833069920539856 VAL: 0.23723956942558289
INFO:root:30
Train: 0.37775924801826477 VAL: 0.3045857846736908
INFO:root:31
Train: 0.33505091071128845 VAL: 0.2558131515979767
INFO:root:32
Train: 0.34520581364631653 VAL: 0.23856934905052185
INFO:root:33
Train: 0.3550005257129669 VAL: 0.42849355936050415
INFO:root:34
Train: 0.33133935928344727 VAL: 0.2512259781360626
INFO:root:35
Train: 0.33383628726005554 VAL: 0.24768763780593872
INFO:root:36
Train: 0.2938697636127472 VAL: 0.2882518768310547
INFO:root:37
Train: 0.319652795791626 VAL: 0.2732031047344208
INFO:root:38
Train: 0.31015926599502563 VAL: 0.26184147596359253
INFO:root:39
Train: 0.3015889525413513 VAL: 0.2669428586959839
INFO:root:40
Train: 0.3143920600414276 VAL: 0.25657621026039124
INFO:root:41
Train: 0.28514376282691956 VAL: 0.2595277726650238
INFO:root:42
Train: 0.3033417761325836 VAL: 0.2698841691017151
INFO:root:43
Train: 0.2891554832458496 VAL: 0.26099032163619995
INFO:root:44
Train: 0.29858285188674927 VAL: 0.2756113111972809
INFO:root:45
Train: 0.2999909818172455 VAL: 0.2773128151893616
INFO:root:46
Train: 0.280527800321579 VAL: 0.27844810485839844
INFO:root:47
Train: 0.27965399622917175 VAL: 0.27942129969596863
INFO:root:48
Train: 0.27162471413612366 VAL: 0.27233439683914185
INFO:root:49
Train: 0.293312132358551 VAL: 0.27242743968963623
INFO:root:BEST VAL: 0.27242743968963623 TEST : 0.34221646189689636
