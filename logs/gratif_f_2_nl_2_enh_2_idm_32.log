INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=2, attn_head=2, latent_dim=32, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 2, 'device': device(type='cuda')}
INFO:root:1
Train: 0.6380656361579895 VAL: 0.5694282650947571
INFO:root:2
Train: 0.5986266732215881 VAL: 0.44922441244125366
INFO:root:3
Train: 0.5152477622032166 VAL: 0.39019039273262024
INFO:root:4
Train: 0.41528066992759705 VAL: 0.3000999689102173
INFO:root:5
Train: 0.35463985800743103 VAL: 0.3204925060272217
INFO:root:6
Train: 0.4186222553253174 VAL: 0.26876771450042725
INFO:root:7
Train: 0.3394717872142792 VAL: 0.2571738660335541
INFO:root:8
Train: 0.3370077610015869 VAL: 0.24394217133522034
INFO:root:9
Train: 0.3385566473007202 VAL: 0.2463357001543045
INFO:root:10
Train: 0.33721768856048584 VAL: 0.23469746112823486
INFO:root:11
Train: 0.3247605562210083 VAL: 0.24488070607185364
INFO:root:12
Train: 0.3080291152000427 VAL: 0.23565547168254852
INFO:root:13
Train: 0.30954328179359436 VAL: 0.2353617548942566
INFO:root:14
Train: 0.2971315383911133 VAL: 0.2357843667268753
INFO:root:15
Train: 0.3171265721321106 VAL: 0.24638502299785614
INFO:root:16
Train: 0.31462183594703674 VAL: 0.23690277338027954
INFO:root:17
Train: 0.31473079323768616 VAL: 0.2445010542869568
INFO:root:18
Train: 0.31739169359207153 VAL: 0.2632562518119812
INFO:root:19
Train: 0.31312718987464905 VAL: 0.2383042573928833
INFO:root:20
Train: 0.31285256147384644 VAL: 0.24376866221427917
INFO:root:21
Train: 0.27834460139274597 VAL: 0.24980999529361725
INFO:root:22
Train: 0.28735536336898804 VAL: 0.2451401650905609
INFO:root:23
Train: 0.3009132146835327 VAL: 0.24492275714874268
INFO:root:24
Train: 0.29750892519950867 VAL: 0.24702370166778564
INFO:root:25
Train: 0.3048853278160095 VAL: 0.24475032091140747
INFO:root:26
Train: 0.30392369627952576 VAL: 0.24353858828544617
INFO:root:27
Train: 0.3073884844779968 VAL: 0.254855751991272
INFO:root:28
Train: 0.30027374625205994 VAL: 0.2461119294166565
INFO:root:29
Train: 0.3064495623111725 VAL: 0.2521629333496094
INFO:root:30
Train: 0.2895994484424591 VAL: 0.24790847301483154
INFO:root:31
Train: 0.2986651659011841 VAL: 0.25225943326950073
INFO:root:32
Train: 0.2979925274848938 VAL: 0.25279754400253296
INFO:root:33
Train: 0.30336907505989075 VAL: 0.2546209990978241
INFO:root:34
Train: 0.3017808496952057 VAL: 0.24994111061096191
INFO:root:35
Train: 0.30074602365493774 VAL: 0.254364550113678
INFO:root:36
Train: 0.3038431704044342 VAL: 0.25250962376594543
INFO:root:37
Train: 0.29399093985557556 VAL: 0.25377780199050903
INFO:root:38
Train: 0.28661802411079407 VAL: 0.25508907437324524
INFO:root:39
Train: 0.30433565378189087 VAL: 0.2549006938934326
INFO:root:40
Train: 0.2993784248828888 VAL: 0.25473523139953613
INFO:root:BEST VAL: 0.25473523139953613 TEST : 0.35188543796539307
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=2, attn_head=2, latent_dim=32, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 2, 'device': device(type='cuda')}
INFO:root:1
Train: 0.4792335033416748 VAL: 0.38791361451148987
INFO:root:2
Train: 0.3814966380596161 VAL: 0.3640078902244568
INFO:root:3
Train: 0.3326115608215332 VAL: 0.30586686730384827
INFO:root:4
Train: 0.30541709065437317 VAL: 0.29800882935523987
INFO:root:5
Train: 0.302520751953125 VAL: 0.2978040277957916
INFO:root:6
Train: 0.30082085728645325 VAL: 0.3021836578845978
INFO:root:7
Train: 0.3002779483795166 VAL: 0.2952972650527954
INFO:root:8
Train: 0.2971183955669403 VAL: 0.2985879182815552
INFO:root:9
Train: 0.2977950870990753 VAL: 0.30238842964172363
INFO:root:10
Train: 0.2974996268749237 VAL: 0.2940833568572998
INFO:root:11
Train: 0.2959401309490204 VAL: 0.29456251859664917
INFO:root:12
Train: 0.2953016757965088 VAL: 0.29210299253463745
INFO:root:13
Train: 0.294654905796051 VAL: 0.2935044765472412
INFO:root:14
Train: 0.2945634722709656 VAL: 0.29456016421318054
INFO:root:15
Train: 0.29418012499809265 VAL: 0.2911451756954193
INFO:root:16
Train: 0.2933935821056366 VAL: 0.2931744456291199
INFO:root:17
Train: 0.29202327132225037 VAL: 0.29057902097702026
INFO:root:18
Train: 0.29291215538978577 VAL: 0.2917119860649109
INFO:root:19
Train: 0.29248112440109253 VAL: 0.2900881767272949
INFO:root:20
Train: 0.29073891043663025 VAL: 0.29040300846099854
INFO:root:21
Train: 0.2903246283531189 VAL: 0.291116863489151
INFO:root:22
Train: 0.2905580401420593 VAL: 0.294197142124176
INFO:root:23
Train: 0.29195886850357056 VAL: 0.28927621245384216
INFO:root:24
Train: 0.29062578082084656 VAL: 0.29123055934906006
INFO:root:25
Train: 0.29025501012802124 VAL: 0.2924191355705261
INFO:root:26
Train: 0.29095324873924255 VAL: 0.28974005579948425
INFO:root:27
Train: 0.2883731722831726 VAL: 0.2891746759414673
INFO:root:28
Train: 0.28846025466918945 VAL: 0.28846070170402527
INFO:root:29
Train: 0.28879284858703613 VAL: 0.289405882358551
INFO:root:30
Train: 0.2890801429748535 VAL: 0.2903446555137634
INFO:root:31
Train: 0.28821229934692383 VAL: 0.28851062059402466
INFO:root:32
Train: 0.2885635197162628 VAL: 0.29158079624176025
INFO:root:33
Train: 0.28901416063308716 VAL: 0.29018300771713257
INFO:root:34
Train: 0.2876490652561188 VAL: 0.2889448404312134
INFO:root:35
Train: 0.2857714295387268 VAL: 0.28853291273117065
INFO:root:36
Train: 0.2867536246776581 VAL: 0.28987693786621094
INFO:root:37
Train: 0.286483496427536 VAL: 0.29072222113609314
INFO:root:38
Train: 0.28732720017433167 VAL: 0.2892135679721832
INFO:root:39
Train: 0.28689977526664734 VAL: 0.2877650856971741
INFO:root:40
Train: 0.2859306037425995 VAL: 0.29114365577697754
INFO:root:41
Train: 0.28649237751960754 VAL: 0.2876069247722626
INFO:root:42
Train: 0.2862373888492584 VAL: 0.2877309024333954
INFO:root:43
Train: 0.28546592593193054 VAL: 0.28794747591018677
INFO:root:44
Train: 0.28549429774284363 VAL: 0.28787529468536377
INFO:root:45
Train: 0.2853465974330902 VAL: 0.2897709012031555
INFO:root:46
Train: 0.2850969135761261 VAL: 0.28776663541793823
INFO:root:47
Train: 0.28491151332855225 VAL: 0.28710442781448364
INFO:root:48
Train: 0.28410854935646057 VAL: 0.28732433915138245
INFO:root:49
Train: 0.2840925455093384 VAL: 0.292153000831604
INFO:root:50
Train: 0.2848268747329712 VAL: 0.28973567485809326
INFO:root:51
Train: 0.28395548462867737 VAL: 0.28880810737609863
INFO:root:52
Train: 0.2824902832508087 VAL: 0.2881395220756531
INFO:root:53
Train: 0.2822367250919342 VAL: 0.28701627254486084
INFO:root:54
Train: 0.282255619764328 VAL: 0.2872938811779022
INFO:root:55
Train: 0.2835787832736969 VAL: 0.2870503067970276
INFO:root:56
Train: 0.2827375531196594 VAL: 0.29154592752456665
INFO:root:57
Train: 0.28261974453926086 VAL: 0.2873347997665405
INFO:root:58
Train: 0.28192561864852905 VAL: 0.28736090660095215
INFO:root:59
Train: 0.28163057565689087 VAL: 0.28738951683044434
INFO:root:60
Train: 0.28241804242134094 VAL: 0.2882148027420044
INFO:root:61
Train: 0.2804988622665405 VAL: 0.28742027282714844
INFO:root:62
Train: 0.2819611728191376 VAL: 0.2876686453819275
INFO:root:63
Train: 0.2803206145763397 VAL: 0.2898918390274048
INFO:root:64
Train: 0.2802535891532898 VAL: 0.28759509325027466
INFO:root:65
Train: 0.27818483114242554 VAL: 0.2867232859134674
INFO:root:66
Train: 0.27805307507514954 VAL: 0.2874705493450165
INFO:root:67
Train: 0.27784696221351624 VAL: 0.28639236092567444
INFO:root:68
Train: 0.27712661027908325 VAL: 0.2874068021774292
INFO:root:69
Train: 0.2767130434513092 VAL: 0.28831201791763306
INFO:root:70
Train: 0.276895672082901 VAL: 0.28802788257598877
INFO:root:71
Train: 0.2773473858833313 VAL: 0.28814932703971863
INFO:root:72
Train: 0.27658790349960327 VAL: 0.28668028116226196
INFO:root:73
Train: 0.27581435441970825 VAL: 0.28664666414260864
INFO:root:74
Train: 0.275407075881958 VAL: 0.2878878116607666
INFO:root:75
Train: 0.2758079469203949 VAL: 0.28826841711997986
INFO:root:76
Train: 0.2754710912704468 VAL: 0.28852584958076477
INFO:root:77
Train: 0.27542611956596375 VAL: 0.28866341710090637
INFO:root:78
Train: 0.274811714887619 VAL: 0.288356751203537
INFO:root:79
Train: 0.27382969856262207 VAL: 0.28720611333847046
INFO:root:80
Train: 0.273670494556427 VAL: 0.28708356618881226
INFO:root:81
Train: 0.2735253572463989 VAL: 0.28829360008239746
INFO:root:82
Train: 0.27319514751434326 VAL: 0.2865712642669678
INFO:root:83
Train: 0.27295997738838196 VAL: 0.2874075770378113
INFO:root:84
Train: 0.2727764844894409 VAL: 0.2872058153152466
INFO:root:85
Train: 0.2725820243358612 VAL: 0.2871716022491455
INFO:root:86
Train: 0.27282074093818665 VAL: 0.28660523891448975
INFO:root:87
Train: 0.2726559042930603 VAL: 0.2873372733592987
INFO:root:88
Train: 0.2725846469402313 VAL: 0.28686219453811646
INFO:root:89
Train: 0.2721715569496155 VAL: 0.287230908870697
INFO:root:90
Train: 0.271294504404068 VAL: 0.2868703603744507
INFO:root:91
Train: 0.27175089716911316 VAL: 0.28711041808128357
INFO:root:92
Train: 0.2709270715713501 VAL: 0.2871478796005249
INFO:root:93
Train: 0.27109816670417786 VAL: 0.28730931878089905
INFO:root:94
Train: 0.27055925130844116 VAL: 0.287225604057312
INFO:root:95
Train: 0.271259605884552 VAL: 0.2876240909099579
INFO:root:96
Train: 0.271316796541214 VAL: 0.2871597409248352
INFO:root:97
Train: 0.27116838097572327 VAL: 0.2868731617927551
INFO:root:BEST VAL: 0.2868731617927551 TEST : 0.28609007596969604
