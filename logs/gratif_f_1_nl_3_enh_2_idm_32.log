INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=1, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.6976932883262634 VAL: 0.6354215741157532
INFO:root:2
Train: 0.5809882283210754 VAL: 0.5856595039367676
INFO:root:3
Train: 0.4715125262737274 VAL: 0.50951087474823
INFO:root:4
Train: 0.4134998321533203 VAL: 0.4451732337474823
INFO:root:5
Train: 0.34731820225715637 VAL: 0.41419392824172974
INFO:root:6
Train: 0.32334959506988525 VAL: 0.40161946415901184
INFO:root:7
Train: 0.3058249056339264 VAL: 0.3948770761489868
INFO:root:8
Train: 0.2992755174636841 VAL: 0.38912642002105713
INFO:root:9
Train: 0.2953178584575653 VAL: 0.38461413979530334
INFO:root:10
Train: 0.2936026453971863 VAL: 0.4026755690574646
INFO:root:11
Train: 0.2931796610355377 VAL: 0.390735387802124
INFO:root:12
Train: 0.2930954098701477 VAL: 0.3830682039260864
INFO:root:13
Train: 0.26356932520866394 VAL: 0.3808726668357849
INFO:root:14
Train: 0.28306326270103455 VAL: 0.3936694860458374
INFO:root:15
Train: 0.29014620184898376 VAL: 0.37859636545181274
INFO:root:16
Train: 0.28933826088905334 VAL: 0.37918949127197266
INFO:root:17
Train: 0.28062212467193604 VAL: 0.3835122585296631
INFO:root:18
Train: 0.2802272439002991 VAL: 0.3799663186073303
INFO:root:19
Train: 0.27648839354515076 VAL: 0.3804718852043152
INFO:root:20
Train: 0.2750460207462311 VAL: 0.3787943124771118
INFO:root:21
Train: 0.28488457202911377 VAL: 0.3780767321586609
INFO:root:22
Train: 0.29048940539360046 VAL: 0.3953621983528137
INFO:root:23
Train: 0.28529325127601624 VAL: 0.38180261850357056
INFO:root:24
Train: 0.29018256068229675 VAL: 0.3783654570579529
INFO:root:25
Train: 0.2742890417575836 VAL: 0.39034026861190796
INFO:root:26
Train: 0.27129825949668884 VAL: 0.37521451711654663
INFO:root:27
Train: 0.27553898096084595 VAL: 0.3818400502204895
INFO:root:28
Train: 0.24378466606140137 VAL: 0.3905108571052551
INFO:root:29
Train: 0.27076420187950134 VAL: 0.37677276134490967
INFO:root:30
Train: 0.2808406949043274 VAL: 0.3775918483734131
INFO:root:31
Train: 0.277905136346817 VAL: 0.3781859278678894
INFO:root:32
Train: 0.26686134934425354 VAL: 0.38434159755706787
INFO:root:33
Train: 0.28040453791618347 VAL: 0.3822515308856964
INFO:root:34
Train: 0.2801916301250458 VAL: 0.38110700249671936
INFO:root:35
Train: 0.2703389525413513 VAL: 0.37781965732574463
INFO:root:36
Train: 0.27389100193977356 VAL: 0.37928640842437744
INFO:root:37
Train: 0.2626127302646637 VAL: 0.3797152638435364
INFO:root:38
Train: 0.2714596092700958 VAL: 0.3764854967594147
INFO:root:39
Train: 0.27093490958213806 VAL: 0.3803294599056244
INFO:root:40
Train: 0.27046501636505127 VAL: 0.37668728828430176
INFO:root:41
Train: 0.2463015764951706 VAL: 0.38098058104515076
INFO:root:42
Train: 0.2740468978881836 VAL: 0.3777535557746887
INFO:root:43
Train: 0.273406982421875 VAL: 0.378261923789978
INFO:root:44
Train: 0.27269673347473145 VAL: 0.37723812460899353
INFO:root:45
Train: 0.2737213373184204 VAL: 0.37818944454193115
INFO:root:46
Train: 0.2698184847831726 VAL: 0.37740516662597656
INFO:root:47
Train: 0.2701839506626129 VAL: 0.376577228307724
INFO:root:48
Train: 0.2522970736026764 VAL: 0.3778412342071533
INFO:root:49
Train: 0.2704940140247345 VAL: 0.3760216236114502
INFO:root:50
Train: 0.26393425464630127 VAL: 0.37749260663986206
INFO:root:51
Train: 0.2612960636615753 VAL: 0.3768725097179413
INFO:root:52
Train: 0.26916220784187317 VAL: 0.377342164516449
INFO:root:53
Train: 0.2712184488773346 VAL: 0.3763749599456787
INFO:root:54
Train: 0.2691552937030792 VAL: 0.37673047184944153
INFO:root:55
Train: 0.26330411434173584 VAL: 0.37715911865234375
INFO:root:56
Train: 0.26450610160827637 VAL: 0.3776424527168274
INFO:root:BEST VAL: 0.3776424527168274 TEST : 0.2525506019592285
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=1, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=3, attn_head=2, latent_dim=32, dataset='physionet2012')
INFO:root:{'input_dim': 37, 'attn_head': 2, 'latent_dim': 32, 'n_layers': 3, 'device': device(type='cuda')}
INFO:root:1
Train: 0.45161938667297363 VAL: 0.3816022276878357
INFO:root:2
Train: 0.3472636640071869 VAL: 0.31016024947166443
INFO:root:3
Train: 0.3083741366863251 VAL: 0.29787003993988037
INFO:root:4
Train: 0.30254948139190674 VAL: 0.2985600233078003
INFO:root:5
Train: 0.2991310656070709 VAL: 0.2957753539085388
INFO:root:6
Train: 0.2985991835594177 VAL: 0.29734066128730774
INFO:root:7
Train: 0.3003545105457306 VAL: 0.2955341637134552
INFO:root:8
Train: 0.299289345741272 VAL: 0.29731565713882446
INFO:root:9
Train: 0.29617568850517273 VAL: 0.2991732060909271
INFO:root:10
Train: 0.29633641242980957 VAL: 0.2951016426086426
INFO:root:11
Train: 0.2947896420955658 VAL: 0.29252132773399353
INFO:root:12
Train: 0.2948027551174164 VAL: 0.29173195362091064
INFO:root:13
Train: 0.2960047721862793 VAL: 0.2931579053401947
INFO:root:14
Train: 0.29280582070350647 VAL: 0.2925340533256531
INFO:root:15
Train: 0.2944434881210327 VAL: 0.2920990586280823
INFO:root:16
Train: 0.291608601808548 VAL: 0.2919754981994629
INFO:root:17
Train: 0.29274529218673706 VAL: 0.292134165763855
INFO:root:18
Train: 0.292338103055954 VAL: 0.29081541299819946
INFO:root:19
Train: 0.29177433252334595 VAL: 0.28953468799591064
INFO:root:20
Train: 0.28988516330718994 VAL: 0.29045534133911133
INFO:root:21
Train: 0.2883903980255127 VAL: 0.2894638180732727
INFO:root:22
Train: 0.28877732157707214 VAL: 0.29360151290893555
INFO:root:23
Train: 0.2912200689315796 VAL: 0.2937798500061035
INFO:root:24
Train: 0.2900092601776123 VAL: 0.2888152003288269
INFO:root:25
Train: 0.28869885206222534 VAL: 0.29006487131118774
INFO:root:26
Train: 0.2880857586860657 VAL: 0.28835877776145935
INFO:root:27
Train: 0.2878071069717407 VAL: 0.28914594650268555
INFO:root:28
Train: 0.28720638155937195 VAL: 0.29421466588974
INFO:root:29
Train: 0.28744083642959595 VAL: 0.2881600856781006
INFO:root:30
Train: 0.2861822843551636 VAL: 0.2890099883079529
INFO:root:31
Train: 0.2888507544994354 VAL: 0.29231178760528564
INFO:root:32
Train: 0.28678616881370544 VAL: 0.28880152106285095
INFO:root:33
Train: 0.2851320207118988 VAL: 0.28983134031295776
INFO:root:34
Train: 0.28514203429222107 VAL: 0.28770557045936584
INFO:root:35
Train: 0.28457143902778625 VAL: 0.289246529340744
INFO:root:36
Train: 0.2846589982509613 VAL: 0.28814440965652466
INFO:root:37
Train: 0.2838344871997833 VAL: 0.287667453289032
INFO:root:38
Train: 0.285143107175827 VAL: 0.28739047050476074
INFO:root:39
Train: 0.28338000178337097 VAL: 0.2876845598220825
INFO:root:40
Train: 0.28265801072120667 VAL: 0.2901149094104767
INFO:root:41
Train: 0.2838402986526489 VAL: 0.2885473966598511
INFO:root:42
Train: 0.28192469477653503 VAL: 0.28801411390304565
INFO:root:43
Train: 0.2828330397605896 VAL: 0.2869546413421631
INFO:root:44
Train: 0.28248724341392517 VAL: 0.2972445487976074
INFO:root:45
Train: 0.2827564477920532 VAL: 0.2881890535354614
INFO:root:46
Train: 0.28189873695373535 VAL: 0.28881990909576416
INFO:root:47
Train: 0.2805978059768677 VAL: 0.2871279716491699
INFO:root:48
Train: 0.2824581265449524 VAL: 0.2874603569507599
INFO:root:49
Train: 0.2807365953922272 VAL: 0.29478105902671814
INFO:root:50
Train: 0.28112632036209106 VAL: 0.28831931948661804
INFO:root:51
Train: 0.27787333726882935 VAL: 0.28831738233566284
INFO:root:52
Train: 0.27873921394348145 VAL: 0.28917843103408813
INFO:root:53
Train: 0.2783907651901245 VAL: 0.2903319001197815
INFO:root:54
Train: 0.2781842350959778 VAL: 0.28756844997406006
INFO:root:55
Train: 0.27507689595222473 VAL: 0.2878596782684326
INFO:root:56
Train: 0.27344247698783875 VAL: 0.28722360730171204
INFO:root:57
Train: 0.27323639392852783 VAL: 0.2877931594848633
INFO:root:58
Train: 0.27298620343208313 VAL: 0.2874748408794403
INFO:root:59
Train: 0.2736036479473114 VAL: 0.28795480728149414
INFO:root:60
Train: 0.27139532566070557 VAL: 0.287801057100296
INFO:root:61
Train: 0.2721227705478668 VAL: 0.2869601845741272
INFO:root:62
Train: 0.2716304659843445 VAL: 0.2893468737602234
INFO:root:63
Train: 0.2712496221065521 VAL: 0.2885185480117798
INFO:root:64
Train: 0.2713494598865509 VAL: 0.2893616557121277
INFO:root:65
Train: 0.27073007822036743 VAL: 0.28854289650917053
INFO:root:66
Train: 0.26827266812324524 VAL: 0.2888006269931793
INFO:root:67
Train: 0.2676430940628052 VAL: 0.2890814542770386
INFO:root:68
Train: 0.2667427957057953 VAL: 0.2893720269203186
INFO:root:69
Train: 0.2669299244880676 VAL: 0.2904667854309082
INFO:root:70
Train: 0.2670963704586029 VAL: 0.2895890176296234
INFO:root:71
Train: 0.2663133144378662 VAL: 0.28926581144332886
INFO:root:72
Train: 0.2660072445869446 VAL: 0.29015129804611206
INFO:root:73
Train: 0.2662622332572937 VAL: 0.28956639766693115
INFO:root:BEST VAL: 0.28956639766693115 TEST : 0.2866170406341553
