INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=64, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 64, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.9474802613258362 VAL: 0.5193393230438232
INFO:root:2
Train: 0.5744642019271851 VAL: 0.6190739274024963
INFO:root:3
Train: 0.44568419456481934 VAL: 0.3110474646091461
INFO:root:4
Train: 0.3650681674480438 VAL: 0.260394424200058
INFO:root:5
Train: 0.32650890946388245 VAL: 0.2481209933757782
INFO:root:6
Train: 0.30530741810798645 VAL: 0.27935659885406494
INFO:root:7
Train: 0.39563584327697754 VAL: 0.2583399713039398
INFO:root:8
Train: 0.3192482590675354 VAL: 0.2621495723724365
INFO:root:9
Train: 0.3563978970050812 VAL: 0.25666677951812744
INFO:root:10
Train: 0.3326488435268402 VAL: 0.25933098793029785
INFO:root:11
Train: 0.3328756093978882 VAL: 0.2790212333202362
INFO:root:12
Train: 0.3117593824863434 VAL: 0.2523341476917267
INFO:root:13
Train: 0.3159951865673065 VAL: 0.2565624415874481
INFO:root:14
Train: 0.30624863505363464 VAL: 0.28065213561058044
INFO:root:15
Train: 0.2832694947719574 VAL: 0.26011231541633606
INFO:root:16
Train: 0.30194053053855896 VAL: 0.2582032084465027
INFO:root:17
Train: 0.3009530305862427 VAL: 0.2787889540195465
INFO:root:18
Train: 0.29651376605033875 VAL: 0.26151761412620544
INFO:root:19
Train: 0.2946006655693054 VAL: 0.2690983712673187
INFO:root:20
Train: 0.29242995381355286 VAL: 0.26881465315818787
INFO:root:21
Train: 0.29021841287612915 VAL: 0.2657947242259979
INFO:root:22
Train: 0.2909391224384308 VAL: 0.275430828332901
INFO:root:23
Train: 0.29110845923423767 VAL: 0.2726711928844452
INFO:root:24
Train: 0.27231109142303467 VAL: 0.28007033467292786
INFO:root:25
Train: 0.28526970744132996 VAL: 0.27373138070106506
INFO:root:26
Train: 0.28736361861228943 VAL: 0.28162848949432373
INFO:root:27
Train: 0.28637731075286865 VAL: 0.2769753634929657
INFO:root:28
Train: 0.27800452709198 VAL: 0.27698299288749695
INFO:root:29
Train: 0.26934564113616943 VAL: 0.27569445967674255
INFO:root:30
Train: 0.28369444608688354 VAL: 0.27495938539505005
INFO:root:31
Train: 0.2711022198200226 VAL: 0.27443408966064453
INFO:root:32
Train: 0.2732798457145691 VAL: 0.27461186051368713
INFO:root:33
Train: 0.2831648290157318 VAL: 0.27739080786705017
INFO:root:34
Train: 0.28790047764778137 VAL: 0.27728399634361267
INFO:root:35
Train: 0.28650963306427 VAL: 0.27679941058158875
INFO:root:BEST VAL: 0.27679941058158875 TEST : 0.3203689157962799
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=64, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 2, 'latent_dim': 64, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.5599976181983948 VAL: 0.5706690549850464
INFO:root:2
Train: 0.4599253237247467 VAL: 0.5277000665664673
INFO:root:3
Train: 0.44862300157546997 VAL: 0.5435423851013184
INFO:root:4
Train: 0.4302669167518616 VAL: 0.4886974096298218
INFO:root:5
Train: 0.4217473864555359 VAL: 0.43727022409439087
INFO:root:6
Train: 0.4032367765903473 VAL: 0.47488123178482056
INFO:root:7
Train: 0.4056291878223419 VAL: 0.457265168428421
INFO:root:8
Train: 0.4003058671951294 VAL: 0.5078844428062439
INFO:root:9
Train: 0.42281270027160645 VAL: 0.46724802255630493
INFO:root:10
Train: 0.39498171210289 VAL: 0.47640183568000793
INFO:root:11
Train: 0.3909665644168854 VAL: 0.4277113676071167
INFO:root:12
Train: 0.38783159852027893 VAL: 0.5783988833427429
INFO:root:13
Train: 0.40677377581596375 VAL: 0.4579024612903595
INFO:root:14
Train: 0.4075670838356018 VAL: 0.450097918510437
INFO:root:15
Train: 0.3937341272830963 VAL: 0.4287264347076416
INFO:root:16
Train: 0.420948326587677 VAL: 0.44943249225616455
INFO:root:17
Train: 0.3882678747177124 VAL: 0.44312983751296997
INFO:root:18
Train: 0.38249415159225464 VAL: 0.4512951076030731
INFO:root:19
Train: 0.3786168098449707 VAL: 0.42123550176620483
INFO:root:20
Train: 0.3778480589389801 VAL: 0.4327564239501953
INFO:root:21
Train: 0.37976041436195374 VAL: 0.5224472880363464
INFO:root:22
Train: 0.38026294112205505 VAL: 0.4300937056541443
INFO:root:23
Train: 0.3692055344581604 VAL: 0.43783462047576904
INFO:root:24
Train: 0.3700401782989502 VAL: 0.4177899956703186
INFO:root:25
Train: 0.38271915912628174 VAL: 0.5110337734222412
INFO:root:26
Train: 0.3834911286830902 VAL: 0.476012259721756
INFO:root:27
Train: 0.3816269338130951 VAL: 0.4122532308101654
INFO:root:28
Train: 0.37007012963294983 VAL: 0.4161911606788635
INFO:root:29
Train: 0.3758617639541626 VAL: 0.44971567392349243
INFO:root:30
Train: 0.3728574514389038 VAL: 0.4254014492034912
INFO:root:31
Train: 0.3687913715839386 VAL: 0.4413604140281677
INFO:root:32
Train: 0.36612385511398315 VAL: 0.4509403705596924
INFO:root:33
Train: 0.3605257570743561 VAL: 0.4265700578689575
INFO:root:34
Train: 0.3579770028591156 VAL: 0.4078870117664337
INFO:root:35
Train: 0.35739725828170776 VAL: 0.4301868975162506
INFO:root:36
Train: 0.36600878834724426 VAL: 0.44789934158325195
INFO:root:37
Train: 0.36373916268348694 VAL: 0.43893003463745117
INFO:root:38
Train: 0.35451436042785645 VAL: 0.44500935077667236
INFO:root:39
Train: 0.36141544580459595 VAL: 0.455598920583725
INFO:root:40
Train: 0.3605414927005768 VAL: 0.44153422117233276
INFO:root:41
Train: 0.356913685798645 VAL: 0.41861146688461304
INFO:root:42
Train: 0.3514578342437744 VAL: 0.4501270651817322
INFO:root:43
Train: 0.3548084497451782 VAL: 0.4339262843132019
INFO:root:44
Train: 0.34833866357803345 VAL: 0.43411868810653687
INFO:root:45
Train: 0.34921231865882874 VAL: 0.43650245666503906
INFO:root:46
Train: 0.3372728228569031 VAL: 0.43346521258354187
INFO:root:47
Train: 0.331053227186203 VAL: 0.4409845471382141
INFO:root:48
Train: 0.33114227652549744 VAL: 0.43612271547317505
INFO:root:49
Train: 0.3302571475505829 VAL: 0.42800867557525635
INFO:root:50
Train: 0.3375928997993469 VAL: 0.43749043345451355
INFO:root:51
Train: 0.33218392729759216 VAL: 0.4113556742668152
INFO:root:52
Train: 0.32875093817710876 VAL: 0.43458008766174316
INFO:root:53
Train: 0.3268343210220337 VAL: 0.4233624339103699
INFO:root:54
Train: 0.3219015300273895 VAL: 0.4336967468261719
INFO:root:55
Train: 0.3159223198890686 VAL: 0.4159603714942932
INFO:root:56
Train: 0.3145690858364105 VAL: 0.44031620025634766
INFO:root:57
Train: 0.3038095533847809 VAL: 0.4394908547401428
INFO:root:58
Train: 0.3008967339992523 VAL: 0.4382396340370178
INFO:root:59
Train: 0.29738175868988037 VAL: 0.44340693950653076
INFO:root:60
Train: 0.2965300679206848 VAL: 0.4290352463722229
INFO:root:61
Train: 0.2920668125152588 VAL: 0.43084418773651123
INFO:root:62
Train: 0.2877725064754486 VAL: 0.4365598261356354
INFO:root:63
Train: 0.28797975182533264 VAL: 0.44239312410354614
INFO:root:64
Train: 0.2849242687225342 VAL: 0.44889992475509644
INFO:root:BEST VAL: 0.44889992475509644 TEST : 0.3898826539516449
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=2, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=64, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 2, 'latent_dim': 64, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.552332878112793 VAL: 0.5363791584968567
INFO:root:2
Train: 0.4517054855823517 VAL: 0.5083473920822144
INFO:root:3
Train: 0.4262270927429199 VAL: 0.471255898475647
INFO:root:4
Train: 0.4110880494117737 VAL: 0.4650781750679016
INFO:root:5
Train: 0.4183206558227539 VAL: 0.4254080355167389
INFO:root:6
Train: 0.4062517285346985 VAL: 0.46562328934669495
INFO:root:7
Train: 0.3966411352157593 VAL: 0.4555010199546814
INFO:root:8
Train: 0.39582961797714233 VAL: 0.45586585998535156
INFO:root:9
Train: 0.3932816684246063 VAL: 0.4822905957698822
INFO:root:10
Train: 0.4412211775779724 VAL: 0.434200644493103
INFO:root:11
Train: 0.39256569743156433 VAL: 0.46548739075660706
INFO:root:12
Train: 0.3845956325531006 VAL: 0.4422529935836792
INFO:root:13
Train: 0.381130576133728 VAL: 0.4440476894378662
INFO:root:14
Train: 0.3768412470817566 VAL: 0.44162997603416443
INFO:root:15
Train: 0.37788498401641846 VAL: 0.41703999042510986
INFO:root:16
Train: 0.37812450528144836 VAL: 0.41646870970726013
INFO:root:17
Train: 0.3747657239437103 VAL: 0.4013511538505554
INFO:root:18
Train: 0.3748019337654114 VAL: 0.45429542660713196
INFO:root:19
Train: 0.37143275141716003 VAL: 0.42085447907447815
INFO:root:20
Train: 0.37060147523880005 VAL: 0.4507654905319214
INFO:root:21
Train: 0.37505805492401123 VAL: 0.4526045024394989
INFO:root:22
Train: 0.36950555443763733 VAL: 0.4396944046020508
INFO:root:23
Train: 0.36624929308891296 VAL: 0.448915034532547
INFO:root:24
Train: 0.37186264991760254 VAL: 0.44261282682418823
INFO:root:25
Train: 0.37160253524780273 VAL: 0.44884762167930603
INFO:root:26
Train: 0.36892202496528625 VAL: 0.4082755744457245
INFO:root:27
Train: 0.36337709426879883 VAL: 0.4010779559612274
INFO:root:28
Train: 0.360695481300354 VAL: 0.4134998023509979
INFO:root:29
Train: 0.3648853898048401 VAL: 0.43048936128616333
INFO:root:30
Train: 0.3796904683113098 VAL: 0.4831044673919678
INFO:root:31
Train: 0.3725124001502991 VAL: 0.43108969926834106
INFO:root:32
Train: 0.37706446647644043 VAL: 0.4196208715438843
INFO:root:33
Train: 0.3852769434452057 VAL: 0.4004656672477722
INFO:root:34
Train: 0.3615624010562897 VAL: 0.3955327272415161
INFO:root:35
Train: 0.3589101731777191 VAL: 0.4338010549545288
INFO:root:36
Train: 0.36273398995399475 VAL: 0.4639599323272705
INFO:root:37
Train: 0.35762283205986023 VAL: 0.4604511260986328
INFO:root:38
Train: 0.35162392258644104 VAL: 0.4606994688510895
INFO:root:39
Train: 0.34991222620010376 VAL: 0.44202351570129395
INFO:root:40
Train: 0.4190502464771271 VAL: 0.47001639008522034
INFO:root:41
Train: 0.4826386272907257 VAL: 0.4739050269126892
INFO:root:42
Train: 0.3965294063091278 VAL: 0.4385315179824829
INFO:root:43
Train: 0.3850199580192566 VAL: 0.45404553413391113
INFO:root:44
Train: 0.3778214752674103 VAL: 0.4550713300704956
INFO:root:45
Train: 0.3766052722930908 VAL: 0.46822574734687805
INFO:root:46
Train: 0.36213192343711853 VAL: 0.45789170265197754
INFO:root:47
Train: 0.35617321729660034 VAL: 0.4611135721206665
INFO:root:48
Train: 0.35297316312789917 VAL: 0.4403369426727295
INFO:root:49
Train: 0.3565298318862915 VAL: 0.46179819107055664
INFO:root:50
Train: 0.3508153259754181 VAL: 0.45693013072013855
INFO:root:51
Train: 0.3478505611419678 VAL: 0.40754225850105286
INFO:root:52
Train: 0.35422471165657043 VAL: 0.4531838893890381
INFO:root:53
Train: 0.3555718660354614 VAL: 0.4393734633922577
INFO:root:54
Train: 0.3515925705432892 VAL: 0.4465327262878418
INFO:root:55
Train: 0.34431782364845276 VAL: 0.4520539939403534
INFO:root:56
Train: 0.34577134251594543 VAL: 0.4527539014816284
INFO:root:57
Train: 0.3431982696056366 VAL: 0.43676748871803284
INFO:root:58
Train: 0.33812573552131653 VAL: 0.4340299069881439
INFO:root:59
Train: 0.33428290486335754 VAL: 0.44043946266174316
INFO:root:60
Train: 0.3308957815170288 VAL: 0.44091153144836426
INFO:root:61
Train: 0.3302575945854187 VAL: 0.4337584972381592
INFO:root:62
Train: 0.32834339141845703 VAL: 0.44408586621284485
INFO:root:63
Train: 0.3228185176849365 VAL: 0.4616033732891083
INFO:root:64
Train: 0.32239145040512085 VAL: 0.45898598432540894
INFO:root:BEST VAL: 0.45898598432540894 TEST : 0.38977083563804626
