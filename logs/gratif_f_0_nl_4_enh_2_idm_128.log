INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=128, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 2, 'latent_dim': 128, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 0.8890806436538696 VAL: 1.3791793584823608
INFO:root:2
Train: 0.730694055557251 VAL: 0.6202582120895386
INFO:root:3
Train: 0.6830106377601624 VAL: 0.5903418660163879
INFO:root:4
Train: 0.6337474584579468 VAL: 0.5637087225914001
INFO:root:5
Train: 0.5717947483062744 VAL: 0.8898401856422424
INFO:root:6
Train: 0.6884253025054932 VAL: 0.6293401718139648
INFO:root:7
Train: 0.6434590220451355 VAL: 0.6314826011657715
INFO:root:8
Train: 0.609556257724762 VAL: 0.585938036441803
INFO:root:9
Train: 1.1781816482543945 VAL: 0.6275096535682678
INFO:root:10
Train: 0.6614739894866943 VAL: 0.6264150738716125
INFO:root:11
Train: 0.5926510691642761 VAL: 0.6245819330215454
INFO:root:12
Train: 0.5532906651496887 VAL: 0.5568947196006775
INFO:root:13
Train: 0.738213062286377 VAL: 0.5875875949859619
INFO:root:14
Train: 0.5714522004127502 VAL: 0.5770881772041321
INFO:root:15
Train: 19.086952209472656 VAL: 140.6822052001953
INFO:root:16
Train: 18314.369140625 VAL: 16.31157112121582
INFO:root:17
Train: 31.956926345825195 VAL: 86.34227752685547
INFO:root:18
Train: 11.696634292602539 VAL: 5.846461296081543
INFO:root:19
Train: 5.601923942565918 VAL: 4.105846881866455
INFO:root:20
Train: 3.767171859741211 VAL: 3.2096457481384277
INFO:root:21
Train: 3.144994020462036 VAL: 3.734973907470703
INFO:root:22
Train: 2.6060659885406494 VAL: 2.1545705795288086
INFO:root:23
Train: 2.2608370780944824 VAL: 1.9844286441802979
INFO:root:24
Train: 2.0091092586517334 VAL: 2.2607638835906982
INFO:root:25
Train: 1.8733526468276978 VAL: 1.8673170804977417
INFO:root:26
Train: 1.8439972400665283 VAL: 1.8981810808181763
INFO:root:27
Train: 1.9286998510360718 VAL: 1.6565743684768677
INFO:root:28
Train: 1.6846659183502197 VAL: 1.59122633934021
INFO:root:29
Train: 1.5967203378677368 VAL: 1.6256531476974487
INFO:root:30
Train: 1.6693971157073975 VAL: 1.6418097019195557
INFO:root:31
Train: 1.5061609745025635 VAL: 1.4113783836364746
INFO:root:32
Train: 1.5295149087905884 VAL: 1.4478837251663208
INFO:root:33
Train: 1.4607899188995361 VAL: 1.425399661064148
INFO:root:34
Train: 1.3891561031341553 VAL: 1.4805824756622314
INFO:root:35
Train: 1.273227572441101 VAL: 1.3138660192489624
INFO:root:36
Train: 1.3251515626907349 VAL: 1.4025285243988037
INFO:root:37
Train: 1.242159128189087 VAL: 1.3363885879516602
INFO:root:38
Train: 1.2258964776992798 VAL: 1.2246798276901245
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=0, batch_size=128, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=4, attn_head=2, latent_dim=128, dataset='ushcn')
INFO:root:{'input_dim': 5, 'attn_head': 2, 'latent_dim': 128, 'n_layers': 4, 'device': device(type='cuda')}
INFO:root:1
Train: 3.0415725708007812 VAL: 1.1782262325286865
INFO:root:2
Train: 0.6753566861152649 VAL: 0.7192134857177734
INFO:root:3
Train: 0.5845614671707153 VAL: 0.6008480787277222
INFO:root:4
Train: 0.4728759229183197 VAL: 0.41929322481155396
INFO:root:5
Train: 0.3549395799636841 VAL: 0.3232381343841553
INFO:root:6
Train: 0.34666678309440613 VAL: 0.4037661850452423
INFO:root:7
Train: 0.34008094668388367 VAL: 0.3376319408416748
INFO:root:8
Train: 0.33702901005744934 VAL: 0.35697463154792786
INFO:root:9
Train: 0.3213271200656891 VAL: 0.39642685651779175
INFO:root:10
Train: 0.2976292669773102 VAL: 0.4932343363761902
INFO:root:11
Train: 0.31796395778656006 VAL: 0.42219728231430054
INFO:root:12
Train: 0.3213619291782379 VAL: 0.3472992181777954
INFO:root:13
Train: 0.289631187915802 VAL: 0.4146217107772827
INFO:root:14
Train: 0.31501954793930054 VAL: 0.3752439320087433
INFO:root:15
Train: 0.3040522336959839 VAL: 0.3472176790237427
INFO:root:16
Train: 0.3004501461982727 VAL: 0.447048157453537
INFO:root:17
Train: 0.3071649968624115 VAL: 0.43947190046310425
INFO:root:18
Train: 0.30463752150535583 VAL: 0.41125422716140747
INFO:root:19
Train: 0.3016313314437866 VAL: 0.43772900104522705
INFO:root:20
Train: 0.2875625789165497 VAL: 0.4011000394821167
INFO:root:21
Train: 0.29489919543266296 VAL: 0.38547128438949585
INFO:root:22
Train: 0.3028539717197418 VAL: 0.4144260883331299
INFO:root:23
Train: 0.3030409514904022 VAL: 0.40760329365730286
INFO:root:24
Train: 0.2976516783237457 VAL: 0.35144954919815063
INFO:root:25
Train: 0.30573198199272156 VAL: 0.35689350962638855
INFO:root:26
Train: 0.29404351115226746 VAL: 0.36483660340309143
INFO:root:27
Train: 0.2893313467502594 VAL: 0.38650578260421753
INFO:root:28
Train: 0.30692052841186523 VAL: 0.38165196776390076
INFO:root:29
Train: 0.3010302186012268 VAL: 0.3591080904006958
INFO:root:30
Train: 0.30315616726875305 VAL: 0.3516586422920227
INFO:root:31
Train: 0.28619256615638733 VAL: 0.3479679822921753
INFO:root:32
Train: 0.29489246010780334 VAL: 0.34920749068260193
INFO:root:33
Train: 0.29204896092414856 VAL: 0.35141220688819885
INFO:root:34
Train: 0.30065539479255676 VAL: 0.3332552909851074
INFO:root:35
Train: 0.29777929186820984 VAL: 0.3362550139427185
INFO:root:BEST VAL: 0.3362550139427185 TEST : 0.20400017499923706
