INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=3, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=1, attn_head=1, latent_dim=64, dataset='mimiciii')
INFO:root:{'input_dim': 96, 'attn_head': 1, 'latent_dim': 64, 'n_layers': 1, 'device': device(type='cuda')}
INFO:root:1
Train: 0.5623894929885864 VAL: 0.4920021891593933
INFO:root:2
Train: 0.4891080856323242 VAL: 0.4669126570224762
INFO:root:3
Train: 0.45764651894569397 VAL: 0.44612687826156616
INFO:root:4
Train: 0.4447033703327179 VAL: 0.42916351556777954
INFO:root:5
Train: 0.43398478627204895 VAL: 0.4196597933769226
INFO:root:6
Train: 0.4521966576576233 VAL: 0.44011861085891724
INFO:root:7
Train: 0.43271729350090027 VAL: 0.41929811239242554
INFO:root:8
Train: 0.4193812310695648 VAL: 0.42261001467704773
INFO:root:9
Train: 0.4150407612323761 VAL: 0.40715134143829346
INFO:root:10
Train: 0.41550976037979126 VAL: 0.4118773937225342
INFO:root:11
Train: 0.4112488925457001 VAL: 0.4026533365249634
INFO:root:12
Train: 0.41048264503479004 VAL: 0.4082736074924469
INFO:root:13
Train: 0.4111414849758148 VAL: 0.40576910972595215
INFO:root:14
Train: 0.41007280349731445 VAL: 0.42201024293899536
INFO:root:15
Train: 0.40293848514556885 VAL: 0.40219786763191223
INFO:root:16
Train: 0.4019032418727875 VAL: 0.39946988224983215
INFO:root:17
Train: 0.40367668867111206 VAL: 0.39910486340522766
INFO:root:18
Train: 0.40177974104881287 VAL: 0.39773088693618774
INFO:root:19
Train: 0.39819708466529846 VAL: 0.39710670709609985
INFO:root:20
Train: 0.39708858728408813 VAL: 0.3990721106529236
INFO:root:21
Train: 0.400092750787735 VAL: 0.39611580967903137
INFO:root:22
Train: 0.39730361104011536 VAL: 0.3951382637023926
INFO:root:23
Train: 0.39858487248420715 VAL: 0.4016675353050232
INFO:root:24
Train: 0.3971278965473175 VAL: 0.4016093611717224
INFO:root:25
Train: 0.39606523513793945 VAL: 0.40056878328323364
INFO:root:26
Train: 0.3953555226325989 VAL: 0.39870983362197876
INFO:root:27
Train: 0.39457350969314575 VAL: 0.4009273052215576
INFO:root:28
Train: 0.3956427276134491 VAL: 0.3954108655452728
INFO:root:29
Train: 0.3947885036468506 VAL: 0.3921828866004944
INFO:root:30
Train: 0.39136406779289246 VAL: 0.39338910579681396
INFO:root:31
Train: 0.38990911841392517 VAL: 0.39517396688461304
INFO:root:32
Train: 0.38940370082855225 VAL: 0.391422301530838
INFO:root:33
Train: 0.3870934247970581 VAL: 0.3881334662437439
INFO:root:34
Train: 0.38496536016464233 VAL: 0.3946880102157593
INFO:root:35
Train: 0.3872985243797302 VAL: 0.38802772760391235
INFO:root:36
Train: 0.38307127356529236 VAL: 0.38665100932121277
INFO:root:37
Train: 0.3868289887905121 VAL: 0.3873111605644226
INFO:root:38
Train: 0.37977516651153564 VAL: 0.3830062747001648
INFO:root:39
Train: 0.38062992691993713 VAL: 0.38610193133354187
INFO:root:40
Train: 0.37880048155784607 VAL: 0.38123375177383423
INFO:root:41
Train: 0.3769228160381317 VAL: 0.3868405222892761
INFO:root:42
Train: 0.3791978061199188 VAL: 0.3828156590461731
INFO:root:43
Train: 0.37792831659317017 VAL: 0.38249462842941284
INFO:root:44
Train: 0.3739416003227234 VAL: 0.3820549249649048
INFO:root:45
Train: 0.3741171956062317 VAL: 0.3800026774406433
INFO:root:46
Train: 0.3743986487388611 VAL: 0.38251811265945435
INFO:root:47
Train: 0.36994773149490356 VAL: 0.3810570538043976
INFO:root:48
Train: 0.37224093079566956 VAL: 0.3824377655982971
INFO:root:49
Train: 0.3680046796798706 VAL: 0.37874680757522583
INFO:root:50
Train: 0.3695983290672302 VAL: 0.37763848900794983
INFO:root:51
Train: 0.3730310797691345 VAL: 0.37979644536972046
INFO:root:52
Train: 0.37032225728034973 VAL: 0.3760836720466614
INFO:root:53
Train: 0.3698452413082123 VAL: 0.3772774338722229
INFO:root:Namespace(quiet=False, run_id=None, config=None, epochs=200, fold=3, batch_size=64, learn_rate=0.001, betas=(0.9, 0.999), weight_decay=0.001, hidden_size=32, kernel_init='skew-symmetric', note='', seed=None, nlayers=1, attn_head=1, latent_dim=64, dataset='mimiciv')
INFO:root:{'input_dim': 100, 'attn_head': 1, 'latent_dim': 64, 'n_layers': 1, 'device': device(type='cuda')}
INFO:root:1
Train: 0.3586502969264984 VAL: 0.3049826920032501
INFO:root:2
Train: 0.2886241674423218 VAL: 0.27582022547721863
INFO:root:3
Train: 0.26978135108947754 VAL: 0.26510554552078247
INFO:root:4
Train: 0.2649408280849457 VAL: 0.26164987683296204
INFO:root:5
Train: 0.2619326412677765 VAL: 0.26957571506500244
INFO:root:6
Train: 0.25453630089759827 VAL: 0.2602294385433197
INFO:root:7
Train: 0.25345656275749207 VAL: 0.2555391192436218
INFO:root:8
Train: 0.25299376249313354 VAL: 0.2627836763858795
INFO:root:9
Train: 0.24993395805358887 VAL: 0.25226569175720215
INFO:root:10
Train: 0.24841395020484924 VAL: 0.25058862566947937
INFO:root:11
Train: 0.24776773154735565 VAL: 0.252705842256546
INFO:root:12
Train: 0.24599352478981018 VAL: 0.2546461224555969
INFO:root:13
Train: 0.2439664751291275 VAL: 0.24919258058071136
INFO:root:14
Train: 0.24540530145168304 VAL: 0.24943807721138
INFO:root:15
Train: 0.24296177923679352 VAL: 0.24653968214988708
INFO:root:16
Train: 0.24068640172481537 VAL: 0.24795827269554138
INFO:root:17
Train: 0.24077081680297852 VAL: 0.24480469524860382
INFO:root:18
Train: 0.24059134721755981 VAL: 0.24629251658916473
INFO:root:19
Train: 0.2387399822473526 VAL: 0.25046882033348083
INFO:root:20
Train: 0.24006180465221405 VAL: 0.2444891780614853
INFO:root:21
Train: 0.2379801869392395 VAL: 0.24372056126594543
INFO:root:22
Train: 0.23765318095684052 VAL: 0.24460545182228088
INFO:root:23
Train: 0.23654966056346893 VAL: 0.2430470585823059
INFO:root:24
Train: 0.23573821783065796 VAL: 0.2425471395254135
INFO:root:25
Train: 0.23420527577400208 VAL: 0.2454180121421814
INFO:root:26
Train: 0.2348850816488266 VAL: 0.24560417234897614
INFO:root:27
Train: 0.23387210071086884 VAL: 0.24196617305278778
INFO:root:28
Train: 0.23209227621555328 VAL: 0.23949913680553436
INFO:root:29
Train: 0.23159123957157135 VAL: 0.24039655923843384
INFO:root:30
Train: 0.23162409663200378 VAL: 0.2410551756620407
INFO:root:31
Train: 0.2306516468524933 VAL: 0.24047327041625977
INFO:root:32
Train: 0.23068954050540924 VAL: 0.23986804485321045
INFO:root:33
Train: 0.23064614832401276 VAL: 0.2401275485754013
INFO:root:34
Train: 0.23037874698638916 VAL: 0.24010801315307617
INFO:root:35
Train: 0.23035065829753876 VAL: 0.24111449718475342
INFO:root:36
Train: 0.22852592170238495 VAL: 0.24146249890327454
INFO:root:37
Train: 0.22845163941383362 VAL: 0.2433633655309677
INFO:root:38
Train: 0.22772540152072906 VAL: 0.24067023396492004
INFO:root:39
Train: 0.22777819633483887 VAL: 0.2398136854171753
INFO:root:40
Train: 0.22393520176410675 VAL: 0.23770293593406677
INFO:root:41
Train: 0.2229364812374115 VAL: 0.23947864770889282
INFO:root:42
Train: 0.2219606190919876 VAL: 0.2375044822692871
INFO:root:43
Train: 0.22295396029949188 VAL: 0.2384551763534546
INFO:root:44
Train: 0.22137458622455597 VAL: 0.23738530278205872
INFO:root:45
Train: 0.22150470316410065 VAL: 0.23863260447978973
INFO:root:46
Train: 0.221527561545372 VAL: 0.2391573190689087
INFO:root:47
Train: 0.22042185068130493 VAL: 0.23954980075359344
INFO:root:48
Train: 0.22127613425254822 VAL: 0.23890428245067596
INFO:root:49
Train: 0.22096462547779083 VAL: 0.23892107605934143
INFO:root:50
Train: 0.21960295736789703 VAL: 0.23944982886314392
INFO:root:51
Train: 0.21893338859081268 VAL: 0.24154552817344666
INFO:root:52
Train: 0.22046031057834625 VAL: 0.23855054378509521
INFO:root:53
Train: 0.21857212483882904 VAL: 0.23672106862068176
INFO:root:54
Train: 0.21988672018051147 VAL: 0.2380726933479309
INFO:root:55
Train: 0.21848787367343903 VAL: 0.23918968439102173
INFO:root:56
Train: 0.21696117520332336 VAL: 0.23934471607208252
INFO:root:57
Train: 0.21763284504413605 VAL: 0.23785436153411865
INFO:root:58
Train: 0.21672102808952332 VAL: 0.23975986242294312
INFO:root:59
Train: 0.215618297457695 VAL: 0.23935875296592712
INFO:root:60
Train: 0.21719707548618317 VAL: 0.2405753880739212
INFO:root:61
Train: 0.21761298179626465 VAL: 0.2388158142566681
INFO:root:62
Train: 0.21598456799983978 VAL: 0.23600631952285767
INFO:root:63
Train: 0.21589387953281403 VAL: 0.2378728985786438
INFO:root:64
Train: 0.2160474807024002 VAL: 0.2398754209280014
INFO:root:65
Train: 0.21635368466377258 VAL: 0.2390635907649994
INFO:root:66
Train: 0.21538236737251282 VAL: 0.23969867825508118
INFO:root:67
Train: 0.21509677171707153 VAL: 0.23926717042922974
INFO:root:68
Train: 0.21507816016674042 VAL: 0.23839831352233887
INFO:root:69
Train: 0.21530258655548096 VAL: 0.24330487847328186
INFO:root:70
Train: 0.21353720128536224 VAL: 0.2407306730747223
INFO:root:71
Train: 0.2126094251871109 VAL: 0.24099817872047424
INFO:root:72
Train: 0.21445196866989136 VAL: 0.2411039024591446
INFO:root:73
Train: 0.21386854350566864 VAL: 0.23855826258659363
INFO:root:74
Train: 0.20978431403636932 VAL: 0.2375735640525818
INFO:root:75
Train: 0.20996709167957306 VAL: 0.23876330256462097
INFO:root:76
Train: 0.20989419519901276 VAL: 0.23883621394634247
INFO:root:77
Train: 0.20853888988494873 VAL: 0.23888075351715088
INFO:root:78
Train: 0.208311066031456 VAL: 0.24183142185211182
INFO:root:79
Train: 0.20931284129619598 VAL: 0.24017304182052612
INFO:root:80
Train: 0.2086554765701294 VAL: 0.23880714178085327
INFO:root:81
Train: 0.20796708762645721 VAL: 0.24077877402305603
INFO:root:82
Train: 0.20781879127025604 VAL: 0.24268904328346252
INFO:root:83
Train: 0.20824284851551056 VAL: 0.24000321328639984
INFO:root:84
Train: 0.2071712613105774 VAL: 0.24159817397594452
INFO:root:85
Train: 0.20525218546390533 VAL: 0.24039623141288757
INFO:root:86
Train: 0.20607244968414307 VAL: 0.24019739031791687
INFO:root:87
Train: 0.20537790656089783 VAL: 0.23959863185882568
INFO:root:88
Train: 0.20563434064388275 VAL: 0.24065035581588745
INFO:root:89
Train: 0.20549237728118896 VAL: 0.24037839472293854
INFO:root:90
Train: 0.20485295355319977 VAL: 0.2402932047843933
INFO:root:91
Train: 0.2042371779680252 VAL: 0.23966854810714722
INFO:root:92
Train: 0.20507510006427765 VAL: 0.24101698398590088
INFO:root:BEST VAL: 0.24101698398590088 TEST : 0.2345590889453888
